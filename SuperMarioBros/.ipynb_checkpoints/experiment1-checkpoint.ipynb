{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import random, datetime, os, copy\n",
    "%reload_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nes_py.wrappers import JoypadSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_super_mario_bros\n",
    "import gym_super_mario_bros.actions as JoypadActions\n",
    "\n",
    "from lib.env_wrappers import EnvWrapperFactory\n",
    "\n",
    "imageShape = (50, 50)\n",
    "actionShape = len(JoypadActions.SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before any transformations: (240, 256, 3)\n",
      "shape after grayscaler: (240, 256)\n",
      "shape after resizer: (50, 50)\n",
      "shape after all transformations: (5, 50, 50)\n",
      "(5, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload \n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, JoypadActions.SIMPLE_MOVEMENT)\n",
    "env = EnvWrapperFactory.convert(env, shape=imageShape)\n",
    "state = env.reset()\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.ForgetfulAgent import ForgetfulAgent\n",
    "from lib.MetricLogger import MetricLogger\n",
    "%reload_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 50, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload \n",
    "agent = ForgetfulAgent(state_shape=env.observation_space.shape, action_shape=actionShape, device=device)\n",
    "save_dir = Path(\"logs\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "save_dir.mkdir(parents=True)\n",
    "logger = MetricLogger(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting episode: 0\n",
      "Episode 0 - Step 1902 - Epsilon 0.9990494518197413 - Mean Reward 1808.0 - Mean Length 1902.0 - Mean Loss 1.169 - Mean Q Value -0.046 - Time Delta 17.921 - Time 2022-03-30T16:19:21\n",
      "{'coins': 1, 'flag_get': False, 'life': 255, 'score': 700, 'stage': 1, 'status': 'small', 'time': 397, 'world': 1, 'x_pos': 1411, 'y_pos': 246}\n",
      "starting episode: 1\n",
      "Episode 1 - Step 3335 - Epsilon 0.9983338890896419 - Mean Reward 1998.0 - Mean Length 1667.5 - Mean Loss 1.213 - Mean Q Value 0.406 - Time Delta 13.9 - Time 2022-03-30T16:19:35\n",
      "{'coins': 2, 'flag_get': False, 'life': 255, 'score': 1000, 'stage': 1, 'status': 'small', 'time': 273, 'world': 1, 'x_pos': 1137, 'y_pos': 254}\n",
      "starting episode: 2\n",
      "Episode 2 - Step 4080 - Epsilon 0.9979620788769844 - Mean Reward 1783.333 - Mean Length 1360.0 - Mean Loss 1.178 - Mean Q Value 0.684 - Time Delta 7.358 - Time 2022-03-30T16:19:42\n",
      "{'coins': 0, 'flag_get': False, 'life': 255, 'score': 400, 'stage': 1, 'status': 'small', 'time': 396, 'world': 1, 'x_pos': 1413, 'y_pos': 253}\n",
      "starting episode: 3\n",
      "Episode 3 - Step 4422 - Epsilon 0.9977914419087287 - Mean Reward 1679.75 - Mean Length 1105.5 - Mean Loss 1.155 - Mean Q Value 0.859 - Time Delta 3.552 - Time 2022-03-30T16:19:46\n",
      "{'coins': 2, 'flag_get': False, 'life': 255, 'score': 600, 'stage': 1, 'status': 'small', 'time': 376, 'world': 1, 'x_pos': 687, 'y_pos': 79}\n",
      "starting episode: 4\n",
      "Episode 4 - Step 4741 - Epsilon 0.9976323068253337 - Mean Reward 1586.0 - Mean Length 948.2 - Mean Loss 1.144 - Mean Q Value 1.002 - Time Delta 3.321 - Time 2022-03-30T16:19:49\n",
      "{'coins': 0, 'flag_get': False, 'life': 255, 'score': 200, 'stage': 1, 'status': 'small', 'time': 388, 'world': 1, 'x_pos': 265, 'y_pos': 79}\n",
      "starting episode: 5\n",
      "Episode 5 - Step 5049 - Epsilon 0.9974786832410089 - Mean Reward 1559.333 - Mean Length 841.5 - Mean Loss 1.149 - Mean Q Value 1.112 - Time Delta 3.357 - Time 2022-03-30T16:19:53\n",
      "{'coins': 1, 'flag_get': False, 'life': 255, 'score': 400, 'stage': 1, 'status': 'small', 'time': 375, 'world': 1, 'x_pos': 707, 'y_pos': 84}\n",
      "starting episode: 6\n",
      "q:1.3303531408309937, loss=1.187265396118164\n",
      "Episode 6 - Step 6010 - Epsilon 0.9969995097446093 - Mean Reward 1485.429 - Mean Length 858.571 - Mean Loss 1.156 - Mean Q Value 1.216 - Time Delta 9.545 - Time 2022-03-30T16:20:02\n",
      "{'coins': 0, 'flag_get': False, 'life': 255, 'score': 200, 'stage': 1, 'status': 'small', 'time': 229, 'world': 1, 'x_pos': 834, 'y_pos': 79}\n",
      "starting episode: 7\n",
      "Episode 7 - Step 6439 - Epsilon 0.9967856762307927 - Mean Reward 1475.875 - Mean Length 804.875 - Mean Loss 1.158 - Mean Q Value 1.287 - Time Delta 4.534 - Time 2022-03-30T16:20:07\n",
      "{'coins': 1, 'flag_get': False, 'life': 255, 'score': 300, 'stage': 1, 'status': 'small', 'time': 363, 'world': 1, 'x_pos': 720, 'y_pos': 79}\n",
      "starting episode: 8\n",
      "Episode 8 - Step 6830 - Epsilon 0.9965908236298552 - Mean Reward 1505.667 - Mean Length 758.889 - Mean Loss 1.165 - Mean Q Value 1.358 - Time Delta 4.062 - Time 2022-03-30T16:20:11\n",
      "{'coins': 1, 'flag_get': False, 'life': 255, 'score': 200, 'stage': 1, 'status': 'small', 'time': 372, 'world': 1, 'x_pos': 658, 'y_pos': 79}\n",
      "starting episode: 9\n",
      "Episode 9 - Step 7707 - Epsilon 0.9961539142438853 - Mean Reward 1531.2 - Mean Length 770.7 - Mean Loss 1.169 - Mean Q Value 1.423 - Time Delta 8.835 - Time 2022-03-30T16:20:20\n",
      "{'coins': 2, 'flag_get': False, 'life': 255, 'score': 500, 'stage': 1, 'status': 'small', 'time': 260, 'world': 1, 'x_pos': 1126, 'y_pos': 253}\n",
      "starting episode: 10\n",
      "Episode 10 - Step 8575 - Epsilon 0.9957216771393161 - Mean Reward 1569.818 - Mean Length 779.545 - Mean Loss 1.17 - Mean Q Value 1.47 - Time Delta 8.931 - Time 2022-03-30T16:20:29\n",
      "{'coins': 2, 'flag_get': False, 'life': 255, 'score': 900, 'stage': 1, 'status': 'small', 'time': 347, 'world': 1, 'x_pos': 898, 'y_pos': 79}\n",
      "starting episode: 11\n",
      "Episode 11 - Step 8884 - Epsilon 0.9955678499852075 - Mean Reward 1537.167 - Mean Length 740.333 - Mean Loss 1.168 - Mean Q Value 1.507 - Time Delta 3.44 - Time 2022-03-30T16:20:32\n",
      "{'coins': 1, 'flag_get': False, 'life': 255, 'score': 300, 'stage': 1, 'status': 'small', 'time': 391, 'world': 1, 'x_pos': 288, 'y_pos': 79}\n",
      "starting episode: 12\n",
      "Episode 12 - Step 10481 - Epsilon 0.9947732061621678 - Mean Reward 1554.231 - Mean Length 806.231 - Mean Loss 1.17 - Mean Q Value 1.584 - Time Delta 14.99 - Time 2022-03-30T16:20:47\n",
      "{'coins': 1, 'flag_get': False, 'life': 255, 'score': 500, 'stage': 1, 'status': 'small', 'time': 392, 'world': 1, 'x_pos': 1411, 'y_pos': 253}\n",
      "starting episode: 13\n",
      "q:2.8142337799072266, loss=1.1371805667877197\n",
      "Episode 13 - Step 11504 - Epsilon 0.9942645096503074 - Mean Reward 1572.071 - Mean Length 821.714 - Mean Loss 1.178 - Mean Q Value 1.742 - Time Delta 10.056 - Time 2022-03-30T16:20:57\n",
      "{'coins': 2, 'flag_get': False, 'life': 255, 'score': 800, 'stage': 1, 'status': 'small', 'time': 397, 'world': 1, 'x_pos': 1406, 'y_pos': 255}\n",
      "starting episode: 14\n",
      "Episode 14 - Step 12377 - Epsilon 0.9938306077893754 - Mean Reward 1554.8 - Mean Length 825.133 - Mean Loss 1.179 - Mean Q Value 1.882 - Time Delta 7.891 - Time 2022-03-30T16:21:05\n",
      "{'coins': 0, 'flag_get': False, 'life': 255, 'score': 500, 'stage': 1, 'status': 'small', 'time': 392, 'world': 1, 'x_pos': 282, 'y_pos': 79}\n",
      "starting episode: 15\n",
      "Episode 15 - Step 14058 - Epsilon 0.9929956438975862 - Mean Reward 1590.188 - Mean Length 878.625 - Mean Loss 1.178 - Mean Q Value 2.003 - Time Delta 15.194 - Time 2022-03-30T16:21:20\n",
      "{'coins': 1, 'flag_get': False, 'life': 255, 'score': 800, 'stage': 1, 'status': 'small', 'time': 244, 'world': 1, 'x_pos': 1133, 'y_pos': 253}\n",
      "starting episode: 16\n",
      "Episode 16 - Step 15747 - Epsilon 0.9921574128597 - Mean Reward 1641.529 - Mean Length 926.294 - Mean Loss 1.172 - Mean Q Value 2.095 - Time Delta 15.062 - Time 2022-03-30T16:21:35\n",
      "{'coins': 1, 'flag_get': False, 'life': 255, 'score': 900, 'stage': 1, 'status': 'small', 'time': 222, 'world': 1, 'x_pos': 1122, 'y_pos': 254}\n",
      "starting episode: 17\n",
      "q:2.879436492919922, loss=1.2099640369415283\n",
      "Episode 17 - Step 17977 - Epsilon 0.9910517735764915 - Mean Reward 1651.778 - Mean Length 998.722 - Mean Loss 1.16 - Mean Q Value 2.148 - Time Delta 20.189 - Time 2022-03-30T16:21:55\n",
      "{'coins': 2, 'flag_get': False, 'life': 255, 'score': 900, 'stage': 1, 'status': 'small', 'time': 14, 'world': 1, 'x_pos': 1120, 'y_pos': 252}\n",
      "starting episode: 18\n",
      "Episode 18 - Step 19273 - Epsilon 0.9904097798951865 - Mean Reward 1649.789 - Mean Length 1014.368 - Mean Loss 1.145 - Mean Q Value 2.168 - Time Delta 12.323 - Time 2022-03-30T16:22:08\n",
      "{'coins': 3, 'flag_get': False, 'life': 255, 'score': 900, 'stage': 1, 'status': 'small', 'time': 390, 'world': 1, 'x_pos': 298, 'y_pos': 79}\n",
      "starting episode: 19\n",
      "q:3.2948341369628906, loss=1.2388101816177368\n",
      "Episode 19 - Step 21762 - Epsilon 0.9891779812619425 - Mean Reward 1664.4 - Mean Length 1088.1 - Mean Loss 1.136 - Mean Q Value 2.217 - Time Delta 23.305 - Time 2022-03-30T16:22:31\n",
      "{'coins': 1, 'flag_get': False, 'life': 255, 'score': 1800, 'stage': 1, 'status': 'small', 'time': 90, 'world': 1, 'x_pos': 1516, 'y_pos': 85}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try training\n",
    "\n",
    "maxStepsPerEpisode = 100_000_000\n",
    "learnCount = 0\n",
    "episodes = 500\n",
    "\n",
    "for eps in range(episodes):\n",
    "    state = env.reset()\n",
    "    print(f\"starting episode: {eps}\")\n",
    "    for i in range(maxStepsPerEpisode):\n",
    "\n",
    "        action = agent.getAction(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        # add to memory\n",
    "        agent.cache(state, next_state, action, reward, done)\n",
    "\n",
    "        q, loss = agent.learn()\n",
    "        \n",
    "        logger.log_step(reward, loss, q)\n",
    "        \n",
    "        state = next_state\n",
    "\n",
    "        if q is not None:\n",
    "            learnCount += 1\n",
    "            if learnCount % 1000 == 0:\n",
    "                print(f\"q:{q}, loss={loss}\")\n",
    "        \n",
    "        if info[\"flag_get\"]:\n",
    "            print(f\"reached a flag\")\n",
    "            print(info)\n",
    "            \n",
    "        if done or info[\"flag_get\"]:\n",
    "            break\n",
    "            \n",
    "    # print(f\"done: {done},\\n info: {info}\")\n",
    "    logger.log_episode()\n",
    "    if eps % 1 == 0:\n",
    "        logger.record(episode=eps, epsilon=agent.exploration_rate, step=agent.current_step)\n",
    "        print(info)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before any transformations: (240, 256, 3)\n",
      "shape after grayscaler: (240, 256)\n",
      "shape after resizer: (50, 50)\n",
      "shape after all transformations: (5, 50, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adhocmaster\\anaconda3\\envs\\gymnes\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, JoypadActions.SIMPLE_MOVEMENT)\n",
    "env = EnvWrapperFactory.convert(env, shape=imageShape)\n",
    "\n",
    "\n",
    "done = True\n",
    "count = 0 \n",
    "for step in range(100000):\n",
    "    if done:\n",
    "        count += 1\n",
    "        if count > 2:\n",
    "            break\n",
    "        state = env.reset()\n",
    "    state, reward, done, info = env.step(agent.getAction(state))\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCheckpoint(name, epoch, model, optimizer):\n",
    "    \n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"exploration_rate\": agent.exploration_rate\n",
    "        \n",
    "    # }, f\"{model.name}-checkpoint-{epoch}\")\n",
    "    }, f\"{name}-checkpoint-{epoch}.pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = (\n",
    "#             save_dir / f\"mario_net_{int(agent.current_step // agent.onlinePeriod)}.chkpt\"\n",
    "#         )\n",
    "# torch.save(\n",
    "#     dict(model=agent.net.state_dict(), exploration_rate=agent.exploration_rate),\n",
    "#     save_path,\n",
    "# )\n",
    "saveCheckpoint(\"ForgetfulAgent-CNN50x50\", 500, agent.net, agent.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
