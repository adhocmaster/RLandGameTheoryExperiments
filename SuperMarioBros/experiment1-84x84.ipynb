{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import random, datetime, os, copy\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n",
    "\n",
    "from time import sleep\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "import gym_super_mario_bros.actions as JoypadActions\n",
    "\n",
    "from lib.env_wrappers import EnvWrapperFactory\n",
    "from agents.ForgetfulAgent import ForgetfulAgent\n",
    "from lib.MetricLogger import MetricLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageShape = (84, 84)\n",
    "actionShape = len(JoypadActions.SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before any transformations: (240, 256, 3)\n",
      "shape after grayscaler: (240, 256)\n",
      "shape after resizer: (84, 84)\n",
      "shape after all transformations: (5, 84, 84)\n",
      "(5, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, JoypadActions.SIMPLE_MOVEMENT)\n",
    "env = EnvWrapperFactory.convert(env, shape=imageShape)\n",
    "state = env.reset()\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 84, 84)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForgetfulAgent-CNN84x84\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "agent = ForgetfulAgent(state_shape=env.observation_space.shape, action_shape=actionShape, device=device, net_name=\"CNN84x84\")\n",
    "save_dir = Path(\"logs\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "save_dir.mkdir(parents=True)\n",
    "logger = MetricLogger(save_dir)\n",
    "print(agent.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 251:   2%|â–Ž         | 250/10000 [42:44<40:40:25, 15.02s/it, episode reward :1425.0, max X: 722] "
     ]
    }
   ],
   "source": [
    "# try training\n",
    "\n",
    "# maxStepsPerEpisode = 10_00_0000\n",
    "learnCount = 0\n",
    "episodes = 10000\n",
    "epsRewards = []\n",
    "with tqdm(range(1, episodes+1)) as tepoch:\n",
    "    for eps in tepoch:\n",
    "        tepoch.set_description(f\"Episode {eps}\")\n",
    "        state = env.reset()\n",
    "        epsReward = 0.0\n",
    "        maxX = 0\n",
    "        # print(f\"starting episode: {eps}\")\n",
    "        # for i in range(maxStepsPerEpisode):\n",
    "        while True:\n",
    "\n",
    "            action = agent.getAction(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            #episode stats\n",
    "            epsReward += reward\n",
    "            if info[\"x_pos\"] > maxX:\n",
    "                maxX = info[\"x_pos\"]\n",
    "                \n",
    "            \n",
    "\n",
    "            # add to memory\n",
    "            agent.cache(state, next_state, action, reward, done)\n",
    "\n",
    "            q, loss = agent.learn()\n",
    "\n",
    "            logger.log_step(reward, loss, q)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "            # if q is not None:\n",
    "            #     learnCount += 1\n",
    "            #     if learnCount % 1000 == 0:\n",
    "            #         print(f\"q:{q}, loss={loss}\")\n",
    "\n",
    "            if info[\"flag_get\"]:\n",
    "                print(f\"reached a flag\")\n",
    "                print(info)\n",
    "\n",
    "            if done or info[\"flag_get\"]:\n",
    "                break\n",
    "\n",
    "        # print(f\"done: {done},\\n info: {info}\")\n",
    "        logger.log_episode()\n",
    "        if eps % 100 == 0:\n",
    "            logger.record(episode=eps, epsilon=agent.exploration_rate, step=agent.current_step)\n",
    "            # print(info)\n",
    "            # agent.save(dir=\"models/\", epoch=eps)\n",
    "        if eps % 1000 == 0:\n",
    "            # print(info)\n",
    "            agent.save(dir=\"models/\", epoch=eps)\n",
    "\n",
    "        epsRewards.append(epsReward)\n",
    "        tepoch.set_postfix_str(f\"episode reward :{epsReward}, max X: {maxX}\")\n",
    "        # print(\"Total reward after episode {} is {}\".format(eps, epsReward))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before any transformations: (240, 256, 3)\n",
      "shape after grayscaler: (240, 256)\n",
      "shape after resizer: (84, 84)\n",
      "shape after all transformations: (5, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, JoypadActions.SIMPLE_MOVEMENT)\n",
    "env = EnvWrapperFactory.convert(env, shape=imageShape)\n",
    "\n",
    "\n",
    "done = True\n",
    "count = 0 \n",
    "for step in range(10000):\n",
    "    if done:\n",
    "        count += 1\n",
    "        if count > 2:\n",
    "            break\n",
    "        state = env.reset()\n",
    "    # state, reward, done, info = env.step(agent.getBestAction(state))\n",
    "    state, reward, done, info = env.step(agent.getAction(state))\n",
    "    # state, reward, done, info = env.step(agent._exploit(state))\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model to models/ForgetfulAgent-CNN84x84-checkpoint-9999.pytorch\n"
     ]
    }
   ],
   "source": [
    "agent.save(dir=\"models/\", epoch=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12048704660553211\n"
     ]
    }
   ],
   "source": [
    "print(agent.exploration_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
