{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import random, datetime, os, copy\n",
    "%reload_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nes_py.wrappers import JoypadSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_super_mario_bros\n",
    "import gym_super_mario_bros.actions as JoypadActions\n",
    "\n",
    "from lib.env_wrappers import EnvWrapperFactory\n",
    "\n",
    "stateShape = (50, 50)\n",
    "actionShape = len(JoypadActions.SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before any transformations: (240, 256, 3)\n",
      "shape after grayscaler: (240, 256)\n",
      "shape after resizer: (50, 50)\n",
      "shape after all transformations: (5, 50, 50)\n",
      "(5, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload \n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, JoypadActions.SIMPLE_MOVEMENT)\n",
    "env = EnvWrapperFactory.convert(env, shape=stateShape)\n",
    "state = env.reset()\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.ForgetfulAgent import ForgetfulAgent\n",
    "%reload_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 50, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload \n",
    "agent = ForgetfulAgent(state_shape=env.observation_space.shape, action_shape=actionShape, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q:0.026198601350188255, loss=0.21926084160804749\n",
      "q:0.6211857795715332, loss=0.6312114000320435\n",
      "q:0.27534550428390503, loss=0.5436283349990845\n",
      "q:0.2912709712982178, loss=0.39244344830513\n",
      "q:0.28735125064849854, loss=0.4541400671005249\n",
      "q:0.32353347539901733, loss=0.4170064628124237\n",
      "q:0.4117383360862732, loss=0.27786481380462646\n",
      "q:0.34249943494796753, loss=0.2962423861026764\n",
      "q:0.25497961044311523, loss=0.3174841105937958\n",
      "q:0.21846255660057068, loss=0.30174094438552856\n",
      "q:0.2077147364616394, loss=0.32695281505584717\n",
      "q:0.2542179226875305, loss=0.5210808515548706\n",
      "q:0.344338595867157, loss=0.332788348197937\n",
      "q:0.3804614543914795, loss=0.488013356924057\n",
      "q:0.44692087173461914, loss=0.25771549344062805\n",
      "q:0.4628807306289673, loss=0.393270879983902\n",
      "q:0.395152747631073, loss=0.5370404720306396\n",
      "q:0.40172868967056274, loss=0.40506109595298767\n",
      "q:0.30543506145477295, loss=0.4653308093547821\n",
      "q:0.30082571506500244, loss=0.3255654573440552\n",
      "q:0.233079195022583, loss=0.2830992043018341\n",
      "q:0.22229944169521332, loss=0.6009874939918518\n",
      "q:0.17446006834506989, loss=0.5217975974082947\n",
      "q:0.2298072874546051, loss=0.5579977631568909\n",
      "q:0.2451580911874771, loss=0.5497257709503174\n",
      "q:0.29181110858917236, loss=0.48048606514930725\n",
      "q:0.3425372540950775, loss=0.31497272849082947\n",
      "q:0.3054206967353821, loss=0.36701035499572754\n",
      "q:0.31746578216552734, loss=0.24439185857772827\n",
      "q:0.25640493631362915, loss=0.38772302865982056\n",
      "q:0.22625938057899475, loss=0.3692716062068939\n",
      "q:0.19653764367103577, loss=0.36167752742767334\n",
      "q:0.14739058911800385, loss=0.37246090173721313\n",
      "q:0.17788302898406982, loss=0.40688222646713257\n",
      "q:0.14493030309677124, loss=0.453077107667923\n",
      "q:0.17236340045928955, loss=0.29193854331970215\n",
      "q:0.14273008704185486, loss=0.10843866318464279\n",
      "q:0.17115096747875214, loss=0.36596643924713135\n",
      "q:0.16440407931804657, loss=0.5186933279037476\n",
      "q:0.14839869737625122, loss=0.3548009395599365\n",
      "q:0.2074035108089447, loss=0.222364142537117\n",
      "q:0.20244517922401428, loss=0.338883638381958\n",
      "q:0.25014644861221313, loss=0.3891409635543823\n",
      "q:0.2568976879119873, loss=0.17088426649570465\n",
      "q:0.2701014578342438, loss=0.37835487723350525\n",
      "q:0.264109343290329, loss=0.1697613000869751\n",
      "q:0.2687363624572754, loss=0.3970790505409241\n",
      "q:0.24468740820884705, loss=0.33331871032714844\n",
      "q:0.25202926993370056, loss=0.2524591386318207\n",
      "q:0.2372724860906601, loss=0.4034077525138855\n",
      "q:0.23112952709197998, loss=0.3435223698616028\n",
      "q:0.23866650462150574, loss=0.4187503159046173\n",
      "q:0.22402432560920715, loss=0.28122758865356445\n",
      "q:0.22868357598781586, loss=0.26477110385894775\n",
      "q:0.23495903611183167, loss=0.328000009059906\n",
      "q:0.2393922507762909, loss=0.3240185081958771\n",
      "q:0.24076351523399353, loss=0.47522133588790894\n",
      "q:0.27116769552230835, loss=0.28512170910835266\n",
      "q:0.2240770012140274, loss=0.31177592277526855\n",
      "q:0.2378089725971222, loss=0.3662877082824707\n",
      "q:0.27513986825942993, loss=0.33949917554855347\n",
      "q:0.2712565064430237, loss=0.3403138220310211\n",
      "q:0.26927196979522705, loss=0.12253876030445099\n",
      "q:0.26100125908851624, loss=0.3254167139530182\n",
      "q:0.2170923501253128, loss=0.33936747908592224\n",
      "q:0.24789215624332428, loss=0.3923894762992859\n",
      "q:0.215642049908638, loss=0.3404274582862854\n",
      "q:0.25067925453186035, loss=0.4576931595802307\n",
      "q:0.2510247230529785, loss=0.3129315972328186\n",
      "q:0.24783021211624146, loss=0.489424467086792\n",
      "q:0.2838892340660095, loss=0.22791720926761627\n",
      "q:0.2624644637107849, loss=0.19328083097934723\n",
      "q:0.2688457667827606, loss=0.35368162393569946\n",
      "q:0.2957531213760376, loss=0.2590605616569519\n",
      "q:0.309651643037796, loss=0.3187863826751709\n",
      "q:0.2889938950538635, loss=0.16880883276462555\n",
      "q:0.28797775506973267, loss=0.26945334672927856\n",
      "q:0.29304760694503784, loss=0.45539718866348267\n",
      "q:0.22237028181552887, loss=0.48294711112976074\n",
      "q:0.24553519487380981, loss=0.36452218890190125\n",
      "q:0.2751394510269165, loss=0.24925118684768677\n",
      "q:0.25892195105552673, loss=0.4613037705421448\n",
      "q:0.26207494735717773, loss=0.3015124797821045\n",
      "q:0.25366947054862976, loss=0.4440777897834778\n",
      "q:0.2244420349597931, loss=0.15853917598724365\n",
      "q:0.30712899565696716, loss=0.27535393834114075\n",
      "q:0.2735047936439514, loss=0.43862971663475037\n",
      "q:0.24704307317733765, loss=0.11364763975143433\n",
      "q:0.2846373915672302, loss=0.3643797039985657\n",
      "q:0.27454426884651184, loss=0.34110701084136963\n",
      "q:0.2779499888420105, loss=0.3724849224090576\n",
      "q:0.2419341504573822, loss=0.2049902379512787\n",
      "q:0.24423819780349731, loss=0.18522407114505768\n",
      "q:0.2540484070777893, loss=0.1571483314037323\n",
      "q:0.23240600526332855, loss=0.2610109746456146\n",
      "q:0.2383512258529663, loss=0.2082194685935974\n",
      "q:0.22127602994441986, loss=0.27599379420280457\n",
      "q:0.2187766432762146, loss=0.10655151307582855\n",
      "q:0.23477809131145477, loss=0.19959937036037445\n",
      "q:0.2130204141139984, loss=0.16742512583732605\n",
      "q:0.18291623890399933, loss=0.31964319944381714\n",
      "q:0.15108075737953186, loss=0.27234748005867004\n",
      "q:0.16396506130695343, loss=0.40846651792526245\n",
      "q:0.16249626874923706, loss=0.38005897402763367\n",
      "q:0.16508549451828003, loss=0.2999127209186554\n",
      "q:0.16050949692726135, loss=0.21149887144565582\n",
      "q:0.17729824781417847, loss=0.20112836360931396\n",
      "q:0.17401449382305145, loss=0.4140893816947937\n",
      "q:0.1733759641647339, loss=0.37316977977752686\n",
      "q:0.1945573091506958, loss=0.1969938576221466\n",
      "q:0.2163095474243164, loss=0.36433035135269165\n",
      "q:0.20663844048976898, loss=0.22310802340507507\n",
      "q:0.21768160164356232, loss=0.13732123374938965\n",
      "q:0.21497774124145508, loss=0.32300272583961487\n",
      "q:0.23457194864749908, loss=0.3273603618144989\n",
      "q:0.22731108963489532, loss=0.22221128642559052\n",
      "q:0.20592926442623138, loss=0.07885561883449554\n",
      "q:0.22766906023025513, loss=0.36778444051742554\n",
      "q:0.21565261483192444, loss=0.31082987785339355\n",
      "q:0.21559172868728638, loss=0.24101820588111877\n",
      "q:0.19456058740615845, loss=0.29483214020729065\n",
      "q:0.17387345433235168, loss=0.2706025242805481\n",
      "q:0.15898551046848297, loss=0.34619683027267456\n",
      "q:0.13666994869709015, loss=0.1507924497127533\n",
      "q:0.14087988436222076, loss=0.1585804522037506\n",
      "q:0.10071365535259247, loss=0.1704544872045517\n",
      "q:0.09381842613220215, loss=0.09041804820299149\n",
      "q:0.09147205203771591, loss=0.18903011083602905\n",
      "q:0.07207267731428146, loss=0.30648940801620483\n",
      "q:0.073836550116539, loss=0.2290314882993698\n",
      "q:0.06089938059449196, loss=0.1954917013645172\n",
      "q:0.06324741244316101, loss=0.4444009065628052\n",
      "q:0.06087376922369003, loss=0.24372632801532745\n",
      "q:0.07363270223140717, loss=0.33080071210861206\n",
      "q:0.08443859219551086, loss=0.10909213870763779\n",
      "q:0.08513933420181274, loss=0.4296211004257202\n",
      "q:0.08803977072238922, loss=0.24430638551712036\n",
      "q:0.09869459271430969, loss=0.33733463287353516\n",
      "q:0.10072942078113556, loss=0.19738899171352386\n",
      "q:0.12180355191230774, loss=0.20975463092327118\n",
      "q:0.12114763259887695, loss=0.20208504796028137\n",
      "q:0.12982282042503357, loss=0.15291985869407654\n",
      "q:0.14020149409770966, loss=0.31065666675567627\n",
      "q:0.12501996755599976, loss=0.35577765107154846\n",
      "q:0.15101882815361023, loss=0.2857103943824768\n",
      "q:0.1470087170600891, loss=0.23475119471549988\n",
      "q:0.15175530314445496, loss=0.3077990412712097\n",
      "q:0.1609487533569336, loss=0.0408516526222229\n",
      "q:0.17719578742980957, loss=0.33384978771209717\n",
      "q:0.1891302466392517, loss=0.37861168384552\n",
      "q:0.2034953236579895, loss=0.3853578567504883\n",
      "q:0.20722392201423645, loss=0.3107106685638428\n",
      "q:0.1932949423789978, loss=0.20382916927337646\n",
      "q:0.21341538429260254, loss=0.2232881337404251\n",
      "q:0.2124059498310089, loss=0.3900396227836609\n",
      "q:0.2148209810256958, loss=0.3263530135154724\n",
      "q:0.21964849531650543, loss=0.26899254322052\n",
      "q:0.21682441234588623, loss=0.19039037823677063\n",
      "q:0.2336680293083191, loss=0.4503074586391449\n",
      "q:0.21842369437217712, loss=0.2431231439113617\n",
      "q:0.2225031852722168, loss=0.19523370265960693\n",
      "q:0.18598082661628723, loss=0.2603994607925415\n",
      "q:0.2057238072156906, loss=0.1504177451133728\n",
      "q:0.22095637023448944, loss=0.0980919823050499\n",
      "q:0.19947412610054016, loss=0.3800526261329651\n",
      "q:0.1924295574426651, loss=0.2929841876029968\n",
      "q:0.17202824354171753, loss=0.2391265630722046\n",
      "q:0.19826965034008026, loss=0.29473334550857544\n",
      "q:0.16747088730335236, loss=0.18065954744815826\n",
      "q:0.1674487292766571, loss=0.2684784531593323\n",
      "q:0.17303559184074402, loss=0.3422778248786926\n",
      "q:0.1628233641386032, loss=0.43705451488494873\n",
      "q:0.1837919056415558, loss=0.3673590421676636\n",
      "q:0.18303638696670532, loss=0.155130535364151\n",
      "q:0.18370479345321655, loss=0.23128332197666168\n",
      "q:0.1628294736146927, loss=0.25752878189086914\n",
      "q:0.17342448234558105, loss=0.4551767408847809\n",
      "q:0.1933802217245102, loss=0.1710047423839569\n",
      "q:0.1681816130876541, loss=0.2354634702205658\n",
      "q:0.1880786418914795, loss=0.2511609196662903\n",
      "q:0.1720423549413681, loss=0.13431598246097565\n",
      "q:0.1742953509092331, loss=0.26793694496154785\n",
      "q:0.1692272126674652, loss=0.2532912492752075\n",
      "q:0.17532776296138763, loss=0.3079438805580139\n",
      "q:0.1702137589454651, loss=0.16561272740364075\n",
      "q:0.16234318912029266, loss=0.1787749081850052\n",
      "q:0.16534072160720825, loss=0.38822123408317566\n",
      "q:0.16008560359477997, loss=0.30601823329925537\n",
      "q:0.15092863142490387, loss=0.14489829540252686\n",
      "q:0.15746310353279114, loss=0.25250446796417236\n",
      "q:0.15214359760284424, loss=0.1961309015750885\n",
      "q:0.155324786901474, loss=0.39969587326049805\n",
      "q:0.1709136664867401, loss=0.15836000442504883\n",
      "q:0.1639145165681839, loss=0.2148900032043457\n",
      "q:0.14969944953918457, loss=0.2055535763502121\n",
      "q:0.15224489569664001, loss=0.33652225136756897\n",
      "q:0.14735844731330872, loss=0.3368719220161438\n",
      "q:0.14512163400650024, loss=0.15506836771965027\n",
      "q:0.1506756842136383, loss=0.21844995021820068\n",
      "q:0.16415008902549744, loss=0.22872164845466614\n",
      "q:0.15379367768764496, loss=0.16285839676856995\n",
      "q:0.15076862275600433, loss=0.13141940534114838\n",
      "q:0.1428399235010147, loss=0.15377891063690186\n",
      "q:0.13985788822174072, loss=0.312822550535202\n",
      "q:0.14435219764709473, loss=0.13868556916713715\n",
      "q:0.1301545351743698, loss=0.08249449729919434\n",
      "q:0.12126082181930542, loss=0.13524165749549866\n",
      "q:0.1298741102218628, loss=0.32694506645202637\n",
      "q:0.11359135061502457, loss=0.2382887601852417\n",
      "q:0.11012621223926544, loss=0.19991876184940338\n",
      "q:0.10512885451316833, loss=0.07596191763877869\n",
      "q:0.10987387597560883, loss=0.15987595915794373\n",
      "q:0.0987430065870285, loss=0.24968495965003967\n",
      "q:0.10267172753810883, loss=0.060880113393068314\n",
      "q:0.08645971864461899, loss=0.1412709653377533\n",
      "q:0.09440261125564575, loss=0.27352625131607056\n",
      "q:0.07986356317996979, loss=0.16753938794136047\n",
      "q:0.08840575069189072, loss=0.2087119221687317\n",
      "q:0.08496581763029099, loss=0.31729066371917725\n",
      "q:0.07975022494792938, loss=0.3473629355430603\n",
      "q:0.09012605249881744, loss=0.24815617501735687\n",
      "q:0.09176871180534363, loss=0.11915114521980286\n",
      "q:0.09323883056640625, loss=0.2574804425239563\n",
      "q:0.10077263414859772, loss=0.09520594775676727\n",
      "q:0.10043761879205704, loss=0.24759091436862946\n",
      "q:0.10129174590110779, loss=0.28594186902046204\n",
      "q:0.10132027417421341, loss=0.3185387849807739\n",
      "q:0.11193601787090302, loss=0.4479660391807556\n",
      "q:0.11390359699726105, loss=0.1999097466468811\n",
      "q:0.11964263021945953, loss=0.25275933742523193\n",
      "q:0.1262846291065216, loss=0.09835125505924225\n",
      "q:0.12329111993312836, loss=0.14200295507907867\n",
      "q:0.12907880544662476, loss=0.11143268644809723\n",
      "q:0.1299162358045578, loss=0.3350004553794861\n",
      "q:0.12645231187343597, loss=0.1053369790315628\n",
      "q:0.12074723094701767, loss=0.11150053143501282\n",
      "q:0.130628302693367, loss=0.24080538749694824\n",
      "q:0.12517061829566956, loss=0.3364357650279999\n",
      "q:0.1205376535654068, loss=0.20108947157859802\n",
      "q:0.11345584690570831, loss=0.15543928742408752\n",
      "q:0.12151132524013519, loss=0.3687286376953125\n",
      "q:0.1176343485713005, loss=0.15646877884864807\n",
      "q:0.11912522464990616, loss=0.19673681259155273\n",
      "q:0.11368443071842194, loss=0.29178398847579956\n",
      "q:0.12135416269302368, loss=0.4284132719039917\n",
      "q:0.11448304355144501, loss=0.345302939414978\n",
      "q:0.11285741627216339, loss=0.23814800381660461\n",
      "q:0.12161685526371002, loss=0.286226749420166\n",
      "q:0.1232241541147232, loss=0.18564128875732422\n",
      "q:0.1241443008184433, loss=0.17923849821090698\n",
      "q:0.12160012871026993, loss=0.1622493863105774\n",
      "q:0.1294507384300232, loss=0.16711042821407318\n",
      "q:0.13094580173492432, loss=0.33965378999710083\n",
      "q:0.12819711863994598, loss=0.07292680442333221\n",
      "q:0.1405090093612671, loss=0.2474995255470276\n",
      "q:0.13156819343566895, loss=0.2103593945503235\n",
      "q:0.1372271180152893, loss=0.19973009824752808\n",
      "q:0.13703776895999908, loss=0.25177910923957825\n",
      "q:0.13484469056129456, loss=0.2917983829975128\n",
      "q:0.13699963688850403, loss=0.14889943599700928\n",
      "q:0.1280248761177063, loss=0.22131752967834473\n",
      "q:0.1285642385482788, loss=0.13750213384628296\n",
      "q:0.11758425831794739, loss=0.12842205166816711\n",
      "q:0.11266004294157028, loss=0.1348988264799118\n",
      "q:0.10494440048933029, loss=0.2691470980644226\n",
      "q:0.09242989122867584, loss=0.35921409726142883\n",
      "q:0.08731406927108765, loss=0.267661988735199\n",
      "q:0.0810922384262085, loss=0.10830648988485336\n",
      "q:0.07875162363052368, loss=0.1248658299446106\n",
      "q:0.0649183988571167, loss=0.11166850477457047\n",
      "q:0.06093820929527283, loss=0.24081385135650635\n",
      "q:0.05846961587667465, loss=0.1680930107831955\n",
      "q:0.05449894815683365, loss=0.16615748405456543\n",
      "q:0.04964275658130646, loss=0.1599676012992859\n",
      "q:0.041864268481731415, loss=0.20648328959941864\n",
      "q:0.0362403504550457, loss=0.09101228415966034\n",
      "q:0.03982856869697571, loss=0.24628882110118866\n",
      "q:0.04211704432964325, loss=0.14974933862686157\n",
      "q:0.030530057847499847, loss=0.11388474702835083\n",
      "q:0.03159751370549202, loss=0.14272001385688782\n",
      "q:0.028956452384591103, loss=0.44329673051834106\n",
      "q:0.026706941425800323, loss=0.2931390702724457\n",
      "q:0.02745964005589485, loss=0.09595242887735367\n",
      "q:0.030148383229970932, loss=0.24883323907852173\n",
      "q:0.027109209448099136, loss=0.18988396227359772\n",
      "q:0.028975658118724823, loss=0.24351215362548828\n",
      "q:0.025873219594359398, loss=0.12932848930358887\n",
      "q:0.026035483926534653, loss=0.14094659686088562\n",
      "q:0.024816688150167465, loss=0.23378348350524902\n",
      "q:0.025884725153446198, loss=0.357584685087204\n",
      "q:0.027971886098384857, loss=0.2488073706626892\n",
      "q:0.0273307953029871, loss=0.21756306290626526\n",
      "q:0.029424596577882767, loss=0.26243826746940613\n",
      "q:0.030033189803361893, loss=0.18616078794002533\n",
      "q:0.03238846734166145, loss=0.15504156053066254\n",
      "q:0.0330115370452404, loss=0.13977780938148499\n",
      "q:0.03809196874499321, loss=0.1393144130706787\n",
      "q:0.04249094799160957, loss=0.3415890038013458\n",
      "q:0.048474013805389404, loss=0.1074891909956932\n",
      "q:0.050677988678216934, loss=0.15285451710224152\n",
      "q:0.053342122584581375, loss=0.21862438321113586\n",
      "q:0.061301931738853455, loss=0.44527721405029297\n",
      "q:0.07046975940465927, loss=0.09562885761260986\n",
      "q:0.0708218514919281, loss=0.15341216325759888\n",
      "q:0.08133301883935928, loss=0.1295359879732132\n",
      "q:0.07394992560148239, loss=0.12358932942152023\n",
      "q:0.07532654702663422, loss=0.16938090324401855\n",
      "q:0.07651337236166, loss=0.3066016435623169\n",
      "q:0.08058270812034607, loss=0.12236469238996506\n",
      "q:0.07525679469108582, loss=0.17643100023269653\n",
      "q:0.09032800793647766, loss=0.31893473863601685\n",
      "q:0.10571002960205078, loss=0.2507879137992859\n",
      "q:0.12933200597763062, loss=0.29166215658187866\n",
      "q:0.16485905647277832, loss=0.21551918983459473\n",
      "q:0.18017873167991638, loss=0.3247000277042389\n",
      "q:0.23231935501098633, loss=0.23786109685897827\n",
      "q:0.2364916056394577, loss=0.25186586380004883\n",
      "q:0.20191024243831635, loss=0.3089750409126282\n",
      "q:0.15977433323860168, loss=0.15960398316383362\n",
      "q:0.131597101688385, loss=0.22898922860622406\n",
      "q:0.12974542379379272, loss=0.08299484848976135\n",
      "q:0.11905815452337265, loss=0.23777849972248077\n",
      "q:0.12333084642887115, loss=0.4190966784954071\n",
      "q:0.10200059413909912, loss=0.1591581404209137\n",
      "q:0.09967859089374542, loss=0.18860867619514465\n",
      "q:0.09296924620866776, loss=0.19737611711025238\n",
      "q:0.09601261466741562, loss=0.25739994645118713\n",
      "q:0.08184045553207397, loss=0.3276662826538086\n",
      "q:0.08976101875305176, loss=0.21414321660995483\n",
      "q:0.0830361396074295, loss=0.07556290924549103\n",
      "q:0.08043142408132553, loss=0.10704341530799866\n",
      "q:0.07901211827993393, loss=0.17348679900169373\n",
      "q:0.08500965684652328, loss=0.15743310749530792\n",
      "q:0.0843166708946228, loss=0.08449152112007141\n",
      "q:0.07213295996189117, loss=0.37997132539749146\n",
      "q:0.0845845639705658, loss=0.21479976177215576\n",
      "q:0.08162786066532135, loss=0.1869097650051117\n",
      "q:0.07414676994085312, loss=0.2791125178337097\n",
      "q:0.0789351612329483, loss=0.3121184706687927\n",
      "q:0.07222123444080353, loss=0.21849305927753448\n",
      "q:0.08213742077350616, loss=0.13460677862167358\n",
      "q:0.07901549339294434, loss=0.33142411708831787\n",
      "q:0.0775749683380127, loss=0.12243233621120453\n",
      "q:0.08263985067605972, loss=0.126844584941864\n",
      "q:0.09267987310886383, loss=0.0910799503326416\n",
      "q:0.08424133062362671, loss=0.17864863574504852\n",
      "q:0.09555869549512863, loss=0.06881190836429596\n",
      "q:0.08830038458108902, loss=0.18484143912792206\n",
      "q:0.09077790379524231, loss=0.25100183486938477\n",
      "q:0.09259529411792755, loss=0.2146005481481552\n",
      "q:0.09275714308023453, loss=0.04644416272640228\n",
      "q:0.08735372871160507, loss=0.098626509308815\n",
      "q:0.08829501271247864, loss=0.2403765469789505\n",
      "q:0.09891780465841293, loss=0.10894651710987091\n",
      "q:0.09498437494039536, loss=0.2601274847984314\n",
      "q:0.0958867222070694, loss=0.09101183712482452\n",
      "q:0.09098897874355316, loss=0.17876753211021423\n",
      "q:0.09906719624996185, loss=0.10913858562707901\n",
      "q:0.10360780358314514, loss=0.033947065472602844\n",
      "q:0.1058046817779541, loss=0.30005156993865967\n",
      "q:0.10432513058185577, loss=0.06493162363767624\n",
      "q:0.0918072760105133, loss=0.2946186065673828\n",
      "q:0.08854347467422485, loss=0.21392183005809784\n",
      "q:0.09604872763156891, loss=0.1559528410434723\n",
      "q:0.08985631167888641, loss=0.23514604568481445\n",
      "q:0.09419326484203339, loss=0.19060897827148438\n",
      "q:0.08865053951740265, loss=0.15630117058753967\n",
      "q:0.08691444247961044, loss=0.15424799919128418\n",
      "q:0.08920694887638092, loss=0.1875152587890625\n",
      "q:0.0904376208782196, loss=0.15548162162303925\n",
      "q:0.08452966809272766, loss=0.2656487226486206\n",
      "q:0.08389074355363846, loss=0.12195923179388046\n",
      "q:0.08205437660217285, loss=0.1375105082988739\n",
      "q:0.07931330054998398, loss=0.018679361790418625\n",
      "q:0.08152969926595688, loss=0.12344284355640411\n",
      "q:0.07921576499938965, loss=0.16799160838127136\n",
      "q:0.08098956197500229, loss=0.12646204233169556\n",
      "q:0.0813189148902893, loss=0.19221234321594238\n",
      "q:0.07953158020973206, loss=0.15392224490642548\n",
      "q:0.07640556991100311, loss=0.26261746883392334\n",
      "q:0.07639312744140625, loss=0.16801118850708008\n",
      "q:0.0778704434633255, loss=0.30390608310699463\n",
      "q:0.0775567889213562, loss=0.3008878231048584\n",
      "q:0.08032576739788055, loss=0.21709424257278442\n",
      "q:0.08217015117406845, loss=0.12346199154853821\n",
      "q:0.08502430468797684, loss=0.24187594652175903\n",
      "q:0.08383775502443314, loss=0.09702460467815399\n",
      "q:0.08479964733123779, loss=0.16678279638290405\n",
      "q:0.08608831465244293, loss=0.15150728821754456\n",
      "q:0.08444973826408386, loss=0.08392159640789032\n",
      "q:0.08315658569335938, loss=0.28708523511886597\n",
      "q:0.08026303350925446, loss=0.09230506420135498\n",
      "q:0.07954465597867966, loss=0.18036754429340363\n",
      "q:0.07968221604824066, loss=0.21652629971504211\n",
      "q:0.07686035335063934, loss=0.19872453808784485\n",
      "q:0.0779920369386673, loss=0.0801101103425026\n",
      "q:0.0785975456237793, loss=0.18180228769779205\n",
      "q:0.07839720696210861, loss=0.30354470014572144\n",
      "q:0.08092747628688812, loss=0.1982203722000122\n",
      "q:0.08480915427207947, loss=0.1854427009820938\n",
      "q:0.08500473201274872, loss=0.33657127618789673\n",
      "q:0.08446557819843292, loss=0.13006922602653503\n",
      "q:0.08736936748027802, loss=0.14027154445648193\n",
      "q:0.08695799857378006, loss=0.07785754650831223\n",
      "q:0.0884704664349556, loss=0.2033764123916626\n",
      "q:0.08864735066890717, loss=0.20203308761119843\n",
      "q:0.08835172653198242, loss=0.11105120182037354\n",
      "q:0.09004773199558258, loss=0.3262752890586853\n",
      "q:0.08914544433355331, loss=0.3625202178955078\n",
      "q:0.0884106308221817, loss=0.16481028497219086\n",
      "q:0.09170903265476227, loss=0.20230057835578918\n",
      "q:0.08939525485038757, loss=0.08062352240085602\n",
      "q:0.08767898380756378, loss=0.3023969233036041\n",
      "q:0.08709870278835297, loss=0.2142198085784912\n",
      "q:0.08862476050853729, loss=0.18714460730552673\n",
      "q:0.08448809385299683, loss=0.15396997332572937\n",
      "q:0.09155885130167007, loss=0.32256755232810974\n",
      "q:0.08645231276750565, loss=0.11858689785003662\n",
      "q:0.08765867352485657, loss=0.09592566639184952\n",
      "q:0.09700748324394226, loss=0.14536407589912415\n",
      "q:0.09278637170791626, loss=0.2337866872549057\n",
      "q:0.09336235374212265, loss=0.1881522685289383\n",
      "q:0.0908849686384201, loss=0.20794904232025146\n",
      "q:0.08894765377044678, loss=0.13677716255187988\n",
      "q:0.09245512634515762, loss=0.2743241488933563\n",
      "q:0.09188546985387802, loss=0.19955402612686157\n",
      "q:0.10091263055801392, loss=0.12259619683027267\n",
      "q:0.0979590117931366, loss=0.3660345673561096\n",
      "q:0.09925784170627594, loss=0.06888691335916519\n",
      "q:0.10462722182273865, loss=0.4255540370941162\n",
      "q:0.10310631990432739, loss=0.1529262512922287\n",
      "q:0.10456050932407379, loss=0.18984262645244598\n",
      "q:0.1115245372056961, loss=0.15251240134239197\n",
      "q:0.10557873547077179, loss=0.158014178276062\n",
      "q:0.1068851500749588, loss=0.051236726343631744\n",
      "q:0.09946845471858978, loss=0.020576396957039833\n",
      "q:0.10116097331047058, loss=0.10886699706315994\n",
      "q:0.10125145316123962, loss=0.27553537487983704\n",
      "q:0.10212814062833786, loss=0.2808917164802551\n",
      "q:0.09974192082881927, loss=0.049413565546274185\n",
      "q:0.09047412872314453, loss=0.07754077762365341\n",
      "q:0.09477051347494125, loss=0.2724016010761261\n",
      "q:0.09152059257030487, loss=0.400945246219635\n",
      "q:0.09278193861246109, loss=0.3008524179458618\n",
      "q:0.08941837400197983, loss=0.06287353485822678\n",
      "q:0.08587224781513214, loss=0.02849842607975006\n",
      "q:0.08831024914979935, loss=0.18423418700695038\n",
      "q:0.08903807401657104, loss=0.14564350247383118\n",
      "q:0.08467677980661392, loss=0.2766456604003906\n",
      "q:0.07814681529998779, loss=0.10670065879821777\n",
      "q:0.080378457903862, loss=0.1090196892619133\n",
      "q:0.08276782184839249, loss=0.21201811730861664\n",
      "q:0.08649110049009323, loss=0.24353143572807312\n",
      "q:0.08202429115772247, loss=0.11264879256486893\n",
      "q:0.08355575799942017, loss=0.13795702159404755\n",
      "q:0.07905901968479156, loss=0.07863858342170715\n",
      "q:0.08325313031673431, loss=0.26419597864151\n",
      "q:0.0781703069806099, loss=0.21754485368728638\n",
      "q:0.07963337004184723, loss=0.12609559297561646\n",
      "q:0.08167648315429688, loss=0.17058655619621277\n",
      "q:0.07785917818546295, loss=0.18225398659706116\n",
      "q:0.0785185843706131, loss=0.1584416925907135\n",
      "q:0.07335825264453888, loss=0.07716679573059082\n",
      "q:0.07522359490394592, loss=0.18975235521793365\n",
      "q:0.07937237620353699, loss=0.3529181182384491\n",
      "q:0.07723301649093628, loss=0.017335571348667145\n",
      "q:0.07539872080087662, loss=0.27951279282569885\n",
      "q:0.07906697690486908, loss=0.15400093793869019\n",
      "q:0.07968249917030334, loss=0.07685600221157074\n",
      "q:0.07043327391147614, loss=0.07733992487192154\n",
      "q:0.07851932942867279, loss=0.08038099855184555\n",
      "q:0.07415600121021271, loss=0.16409045457839966\n",
      "q:0.07232543081045151, loss=0.1448885202407837\n",
      "q:0.07637739181518555, loss=0.2961399257183075\n",
      "q:0.06083869934082031, loss=0.14545994997024536\n",
      "q:0.07193000614643097, loss=0.110431008040905\n",
      "q:0.07359188795089722, loss=0.04622102156281471\n",
      "q:0.07065168023109436, loss=0.05018804594874382\n",
      "q:0.06123290956020355, loss=0.11994270980358124\n",
      "q:0.06362874805927277, loss=0.12555328011512756\n",
      "q:0.057832490652799606, loss=0.07555560022592545\n",
      "q:0.06428548693656921, loss=0.21545474231243134\n",
      "q:0.06278243660926819, loss=0.11082525551319122\n",
      "q:0.06507828086614609, loss=0.12435604631900787\n",
      "q:0.0641724169254303, loss=0.2632691264152527\n",
      "q:0.057166267186403275, loss=0.15232160687446594\n",
      "q:0.05953394994139671, loss=0.1906021535396576\n",
      "q:0.05984028801321983, loss=0.28983619809150696\n",
      "q:0.06958579272031784, loss=0.29237279295921326\n",
      "q:0.06963959336280823, loss=0.15682262182235718\n",
      "q:0.07145807147026062, loss=0.1734890639781952\n",
      "q:0.06458848714828491, loss=0.10516484081745148\n",
      "q:0.06508340686559677, loss=0.15292306244373322\n",
      "q:0.07133112847805023, loss=0.20471937954425812\n",
      "q:0.07204040884971619, loss=0.11443378031253815\n",
      "q:0.06546171754598618, loss=0.142786905169487\n",
      "q:0.06528718769550323, loss=0.1275443434715271\n",
      "q:0.06467984616756439, loss=0.15511932969093323\n",
      "q:0.060719169676303864, loss=0.21824809908866882\n",
      "q:0.06272371113300323, loss=0.13660749793052673\n",
      "q:0.0647892951965332, loss=0.10845469683408737\n",
      "q:0.06125083565711975, loss=0.1736077070236206\n",
      "q:0.061898380517959595, loss=0.12589246034622192\n",
      "q:0.06489171087741852, loss=0.12045186758041382\n",
      "q:0.061279743909835815, loss=0.1548875868320465\n",
      "q:0.05922578647732735, loss=0.2030063271522522\n",
      "q:0.056323643773794174, loss=0.03275366127490997\n",
      "q:0.05932915210723877, loss=0.1070023626089096\n",
      "q:0.06099224090576172, loss=0.20210856199264526\n",
      "q:0.060707177966833115, loss=0.14082129299640656\n",
      "q:0.06196751073002815, loss=0.07858513295650482\n",
      "q:0.06052054092288017, loss=0.09415953606367111\n",
      "q:0.05734878033399582, loss=0.04751355201005936\n",
      "q:0.05967658758163452, loss=0.20109204947948456\n",
      "q:0.05588299036026001, loss=0.06217481940984726\n",
      "q:0.05303572490811348, loss=0.19989138841629028\n",
      "q:0.05539514124393463, loss=0.23084191977977753\n",
      "q:0.056435395032167435, loss=0.05038455128669739\n",
      "q:0.05698036402463913, loss=0.2150164693593979\n",
      "q:0.05947280675172806, loss=0.12296489626169205\n",
      "q:0.05739638954401016, loss=0.09201826900243759\n",
      "q:0.058483585715293884, loss=0.09339450299739838\n",
      "q:0.05527685582637787, loss=0.03003019280731678\n",
      "q:0.055506203323602676, loss=0.13956263661384583\n",
      "q:0.06211598962545395, loss=0.04719323664903641\n",
      "q:0.05544986575841904, loss=0.17227408289909363\n",
      "q:0.052809491753578186, loss=0.12248706817626953\n",
      "q:0.058242298662662506, loss=0.08091674745082855\n",
      "q:0.05749599635601044, loss=0.09169123321771622\n",
      "q:0.058440640568733215, loss=0.2016289234161377\n",
      "q:0.06222279369831085, loss=0.1407453417778015\n",
      "q:0.05513446033000946, loss=0.12346044182777405\n",
      "q:0.06367332488298416, loss=0.03050335869193077\n",
      "q:0.06162288784980774, loss=0.05098242312669754\n",
      "q:0.06295251846313477, loss=0.12296734750270844\n",
      "q:0.06183888390660286, loss=0.1837519109249115\n",
      "q:0.06380726397037506, loss=0.40128517150878906\n",
      "q:0.06324661523103714, loss=0.12695211172103882\n",
      "q:0.06414994597434998, loss=0.046085719019174576\n",
      "q:0.06636127084493637, loss=0.1400614082813263\n",
      "q:0.06980396807193756, loss=0.17087718844413757\n",
      "q:0.07026085257530212, loss=0.15425804257392883\n",
      "q:0.06852396577596664, loss=0.09269148111343384\n",
      "q:0.07214135676622391, loss=0.07448885589838028\n",
      "q:0.06954807043075562, loss=0.21948114037513733\n",
      "q:0.07404347509145737, loss=0.1373721957206726\n",
      "q:0.07234339416027069, loss=0.14103227853775024\n",
      "q:0.06995505094528198, loss=0.10909764468669891\n",
      "q:0.0762752890586853, loss=0.12564752995967865\n",
      "q:0.07115629315376282, loss=0.09290286153554916\n",
      "q:0.074895478785038, loss=0.136550173163414\n",
      "q:0.07170922309160233, loss=0.12614987790584564\n",
      "q:0.07075877487659454, loss=0.264857679605484\n",
      "q:0.07107479870319366, loss=0.014762913808226585\n",
      "q:0.0700848177075386, loss=0.19886472821235657\n",
      "q:0.07430418580770493, loss=0.1870345175266266\n",
      "q:0.07349171489477158, loss=0.08058543503284454\n",
      "q:0.06936655193567276, loss=0.07889382541179657\n",
      "q:0.07073663175106049, loss=0.17095406353473663\n",
      "q:0.06890028715133667, loss=0.09723292291164398\n",
      "q:0.06710739433765411, loss=0.15606209635734558\n",
      "q:0.06556520611047745, loss=0.15790662169456482\n",
      "q:0.06577334553003311, loss=0.1391841322183609\n",
      "q:0.06274254620075226, loss=0.18717309832572937\n",
      "q:0.06243632733821869, loss=0.14180642366409302\n",
      "q:0.06273749470710754, loss=0.12432549893856049\n",
      "q:0.05984291434288025, loss=0.06304681301116943\n",
      "q:0.05857139080762863, loss=0.15620316565036774\n",
      "q:0.059421390295028687, loss=0.07729572057723999\n",
      "q:0.06284384429454803, loss=0.13928741216659546\n",
      "q:0.058358706533908844, loss=0.017041880637407303\n",
      "q:0.06015830487012863, loss=0.12237223982810974\n",
      "q:0.06050192937254906, loss=0.09156955778598785\n",
      "q:0.057762544602155685, loss=0.28197574615478516\n",
      "q:0.05630074441432953, loss=0.12510353326797485\n",
      "q:0.05718126893043518, loss=0.06279713660478592\n",
      "q:0.055455293506383896, loss=0.21657907962799072\n",
      "q:0.05328703671693802, loss=0.3870363235473633\n",
      "q:0.05240463465452194, loss=0.09565483778715134\n",
      "q:0.05761948972940445, loss=0.06267933547496796\n",
      "q:0.05717270448803902, loss=0.12402044236660004\n",
      "q:0.057287514209747314, loss=0.2043212354183197\n",
      "q:0.056689053773880005, loss=0.09215287119150162\n",
      "q:0.05380895733833313, loss=0.12341998517513275\n",
      "q:0.051486700773239136, loss=0.12598729133605957\n",
      "q:0.0520249679684639, loss=0.12462636083364487\n",
      "q:0.050090473145246506, loss=0.09648339450359344\n",
      "q:0.052305132150650024, loss=0.12469566613435745\n",
      "q:0.05312468111515045, loss=0.1490551382303238\n",
      "q:0.053701251745224, loss=0.18548887968063354\n",
      "q:0.05105932801961899, loss=0.12543535232543945\n",
      "q:0.05388926714658737, loss=0.09661630541086197\n",
      "q:0.049617886543273926, loss=0.07942360639572144\n",
      "q:0.049909140914678574, loss=0.24839049577713013\n",
      "q:0.0512973815202713, loss=0.18552720546722412\n",
      "q:0.05260273814201355, loss=0.10957664251327515\n",
      "q:0.050471581518650055, loss=0.21511496603488922\n",
      "q:0.05424162372946739, loss=0.25914013385772705\n",
      "q:0.05347810685634613, loss=0.2767426371574402\n",
      "q:0.051033586263656616, loss=0.09426942467689514\n",
      "q:0.057493869215250015, loss=0.17127889394760132\n",
      "q:0.05744238197803497, loss=0.0752168670296669\n",
      "q:0.059915170073509216, loss=0.2022930085659027\n",
      "q:0.057570330798625946, loss=0.21736419200897217\n",
      "q:0.0626344233751297, loss=0.16734863817691803\n",
      "q:0.06275993585586548, loss=0.07805085182189941\n",
      "q:0.06432847678661346, loss=0.11187775433063507\n",
      "q:0.06504891812801361, loss=0.2627655267715454\n",
      "q:0.06760390102863312, loss=0.17087826132774353\n",
      "q:0.0653887391090393, loss=0.09659065306186676\n",
      "q:0.06811873614788055, loss=0.11308708786964417\n",
      "q:0.06694099307060242, loss=0.29559266567230225\n",
      "q:0.06882767379283905, loss=0.17064452171325684\n",
      "q:0.06566246598958969, loss=0.27579155564308167\n",
      "q:0.0664900690317154, loss=0.2585257887840271\n",
      "q:0.062458544969558716, loss=0.2315705120563507\n",
      "q:0.07336128503084183, loss=0.15417951345443726\n",
      "q:0.07157247513532639, loss=0.1335330307483673\n",
      "q:0.07341668009757996, loss=0.25867289304733276\n",
      "q:0.07539404928684235, loss=0.20509777963161469\n",
      "q:0.06967823207378387, loss=0.24745416641235352\n",
      "q:0.08194366097450256, loss=0.1435832530260086\n",
      "q:0.08011481165885925, loss=0.20474165678024292\n",
      "q:0.08557590842247009, loss=0.11214970797300339\n",
      "q:0.08397774398326874, loss=0.114798903465271\n",
      "q:0.081659696996212, loss=0.07321567088365555\n",
      "q:0.08262306451797485, loss=0.18387916684150696\n",
      "q:0.0814455896615982, loss=0.048999641090631485\n",
      "q:0.08349091559648514, loss=0.12228818237781525\n",
      "q:0.08599963039159775, loss=0.06042004004120827\n",
      "q:0.07843334227800369, loss=0.24760709702968597\n",
      "q:0.08490993082523346, loss=0.06828512251377106\n",
      "q:0.07657933980226517, loss=0.11033125221729279\n",
      "q:0.07932950556278229, loss=0.1257001906633377\n",
      "q:0.07644045352935791, loss=0.17846284806728363\n",
      "q:0.07648147642612457, loss=0.028819622471928596\n",
      "q:0.07419245690107346, loss=0.052570369094610214\n",
      "q:0.0710599422454834, loss=0.0799098089337349\n",
      "q:0.06797587871551514, loss=0.2672324776649475\n",
      "q:0.05941475182771683, loss=0.04866991937160492\n",
      "q:0.05991220101714134, loss=0.09164819121360779\n",
      "q:0.05842166021466255, loss=0.1992005854845047\n",
      "q:0.05884409695863724, loss=0.15601347386837006\n",
      "q:0.057139307260513306, loss=0.23182056844234467\n",
      "q:0.05874290317296982, loss=0.20243142545223236\n",
      "q:0.05876617133617401, loss=0.22039034962654114\n",
      "q:0.051496557891368866, loss=0.030910219997167587\n",
      "q:0.04951287433505058, loss=0.12681220471858978\n",
      "q:0.05527708679437637, loss=0.1415984183549881\n",
      "q:0.04721575230360031, loss=0.046734873205423355\n",
      "q:0.047926321625709534, loss=0.047785356640815735\n",
      "q:0.049299050122499466, loss=0.0911593958735466\n",
      "q:0.04682574048638344, loss=0.17112180590629578\n",
      "q:0.04617055505514145, loss=0.21786615252494812\n",
      "q:0.049881462007761, loss=0.18642432987689972\n",
      "q:0.04295312613248825, loss=0.14001071453094482\n",
      "q:0.05119004845619202, loss=0.2989819049835205\n",
      "q:0.04286712408065796, loss=0.1260782927274704\n",
      "q:0.04736869037151337, loss=0.18360111117362976\n",
      "q:0.05094318091869354, loss=0.24734972417354584\n",
      "q:0.0497661791741848, loss=0.11007581651210785\n",
      "q:0.04919588565826416, loss=0.10710027813911438\n",
      "q:0.051656574010849, loss=0.1749819815158844\n",
      "q:0.05154070258140564, loss=0.08096803724765778\n",
      "q:0.046589240431785583, loss=0.21615716814994812\n",
      "q:0.05233130231499672, loss=0.07818792760372162\n",
      "q:0.049864087253808975, loss=0.09324827790260315\n",
      "q:0.04696950316429138, loss=0.10695226490497589\n",
      "q:0.05101103335618973, loss=0.07897458225488663\n",
      "q:0.05027318000793457, loss=0.11236559599637985\n",
      "q:0.049664370715618134, loss=0.09438696503639221\n",
      "q:0.04858594387769699, loss=0.03140620142221451\n",
      "q:0.04989678040146828, loss=0.1542835235595703\n",
      "q:0.04631972685456276, loss=0.07904109358787537\n",
      "q:0.04525977373123169, loss=0.06399110704660416\n",
      "q:0.04531542956829071, loss=0.1264655441045761\n",
      "q:0.04620979726314545, loss=0.13962045311927795\n",
      "q:0.046067968010902405, loss=0.1722363531589508\n",
      "q:0.04582693427801132, loss=0.11098373681306839\n",
      "q:0.040338825434446335, loss=0.1717931181192398\n",
      "q:0.03989686816930771, loss=0.327983558177948\n",
      "q:0.03723875433206558, loss=0.1865832805633545\n",
      "q:0.03536856174468994, loss=0.07868029177188873\n",
      "q:0.03718601167201996, loss=0.10905230045318604\n",
      "q:0.03376597538590431, loss=0.06149565801024437\n",
      "q:0.03536425903439522, loss=0.0777120590209961\n",
      "q:0.036893196403980255, loss=0.17140576243400574\n",
      "q:0.03660443425178528, loss=0.141305074095726\n",
      "q:0.03661128133535385, loss=0.17234009504318237\n",
      "q:0.03346499055624008, loss=0.1250453144311905\n",
      "q:0.03105742670595646, loss=0.21890142560005188\n",
      "q:0.03522420674562454, loss=0.10815079510211945\n",
      "q:0.03463447839021683, loss=0.20350991189479828\n",
      "q:0.035201527178287506, loss=0.10949313640594482\n",
      "q:0.0344986617565155, loss=0.11062025278806686\n",
      "q:0.033643826842308044, loss=0.15691199898719788\n",
      "q:0.03301549702882767, loss=0.03052816353738308\n",
      "q:0.03222346305847168, loss=0.12523381412029266\n",
      "q:0.03441545367240906, loss=0.03123224340379238\n",
      "q:0.033831533044576645, loss=0.21720075607299805\n",
      "q:0.03279691934585571, loss=0.233972430229187\n",
      "q:0.03090042620897293, loss=0.046450015157461166\n",
      "q:0.0344327911734581, loss=0.09536101669073105\n",
      "q:0.03485029190778732, loss=0.21777907013893127\n",
      "q:0.03501850739121437, loss=0.1251450628042221\n",
      "q:0.03373061865568161, loss=0.07777175307273865\n",
      "q:0.03514201194047928, loss=0.2806171178817749\n",
      "q:0.036530040204524994, loss=0.12401725351810455\n",
      "q:0.03615403547883034, loss=0.14123111963272095\n",
      "q:0.03803342953324318, loss=0.1698327362537384\n",
      "q:0.03965520113706589, loss=0.20252445340156555\n",
      "q:0.036711376160383224, loss=0.12407571077346802\n",
      "q:0.035058651119470596, loss=0.138808473944664\n",
      "q:0.04000249132514, loss=0.12488986551761627\n",
      "q:0.04019836336374283, loss=0.046223413199186325\n",
      "q:0.04160108417272568, loss=0.16995127499103546\n",
      "q:0.039499834179878235, loss=0.0643155425786972\n",
      "q:0.041179340332746506, loss=0.24894098937511444\n",
      "q:0.04268233850598335, loss=0.29570654034614563\n",
      "q:0.04411280155181885, loss=0.2352445423603058\n",
      "q:0.043831005692481995, loss=0.09606246650218964\n",
      "q:0.04049931466579437, loss=0.17017987370491028\n",
      "q:0.0438741110265255, loss=0.09293435513973236\n",
      "q:0.04697929322719574, loss=0.11069010198116302\n",
      "q:0.04523087292909622, loss=0.15848436951637268\n",
      "q:0.044203683733940125, loss=0.23090201616287231\n",
      "q:0.04538021981716156, loss=0.12157733738422394\n",
      "q:0.04739198461174965, loss=0.1712898313999176\n",
      "q:0.04586648941040039, loss=0.21815228462219238\n",
      "q:0.04634985327720642, loss=0.15655526518821716\n",
      "q:0.04848386347293854, loss=0.03165695071220398\n",
      "q:0.048476822674274445, loss=0.16731032729148865\n",
      "q:0.04916469752788544, loss=0.15597793459892273\n",
      "q:0.050123680382966995, loss=0.06319499015808105\n",
      "q:0.04704663157463074, loss=0.09266644716262817\n",
      "q:0.04674307256937027, loss=0.21709248423576355\n",
      "q:0.04665025696158409, loss=0.1259917914867401\n",
      "q:0.051506705582141876, loss=0.06441312283277512\n",
      "q:0.05257895961403847, loss=0.16981686651706696\n",
      "q:0.05534735321998596, loss=0.04620223864912987\n",
      "q:0.054849959909915924, loss=0.0940735787153244\n",
      "q:0.05371685326099396, loss=0.1087907999753952\n",
      "q:0.055001795291900635, loss=0.19951894879341125\n",
      "q:0.05775734782218933, loss=0.08279801905155182\n",
      "q:0.056394062936306, loss=0.07759790867567062\n",
      "q:0.057760003954172134, loss=0.0006178744952194393\n",
      "q:0.05353201925754547, loss=0.03434644639492035\n",
      "q:0.055192697793245316, loss=0.04665397107601166\n",
      "q:0.05395154282450676, loss=0.032835960388183594\n",
      "q:0.05303923413157463, loss=0.061256103217601776\n",
      "q:0.05428602546453476, loss=0.17090407013893127\n",
      "q:0.054695531725883484, loss=0.07756920158863068\n",
      "q:0.05376537889242172, loss=0.18811243772506714\n",
      "q:0.05500999093055725, loss=0.12392398715019226\n",
      "q:0.05314001068472862, loss=0.07720991224050522\n",
      "q:0.05479343235492706, loss=0.12511183321475983\n",
      "q:0.053435251116752625, loss=0.03174704313278198\n",
      "q:0.0529082790017128, loss=0.1562384068965912\n",
      "q:0.05125216394662857, loss=0.09170475602149963\n",
      "q:0.05113569647073746, loss=0.10973590612411499\n",
      "q:0.05281183868646622, loss=0.12635530531406403\n",
      "q:0.051949527114629745, loss=0.18638378381729126\n",
      "q:0.049956560134887695, loss=0.014735348522663116\n",
      "q:0.050141576677560806, loss=0.12434034794569016\n",
      "q:0.049441054463386536, loss=0.08001147210597992\n",
      "q:0.050692230463027954, loss=0.24974854290485382\n",
      "q:0.04693831130862236, loss=0.23318584263324738\n",
      "q:0.04711884260177612, loss=0.04788369685411453\n",
      "q:0.04684631526470184, loss=0.0787525326013565\n",
      "q:0.044958069920539856, loss=0.17265623807907104\n",
      "q:0.04553556069731712, loss=0.06278900802135468\n",
      "q:0.04560001194477081, loss=0.10970249772071838\n",
      "q:0.041895799338817596, loss=0.1688857078552246\n",
      "q:0.04503028839826584, loss=0.10963183641433716\n",
      "q:0.04032888263463974, loss=0.23206448554992676\n",
      "q:0.043587274849414825, loss=0.04746605455875397\n",
      "q:0.045093078166246414, loss=0.1561131328344345\n",
      "q:0.041324615478515625, loss=0.09363597631454468\n",
      "q:0.039558134973049164, loss=0.17257772386074066\n",
      "q:0.04079775512218475, loss=0.1382414996623993\n",
      "q:0.036766380071640015, loss=0.17085842788219452\n",
      "q:0.041161514818668365, loss=0.17149297893047333\n",
      "q:0.04091625660657883, loss=0.04698885977268219\n",
      "q:0.037466637790203094, loss=0.07849779725074768\n",
      "q:0.043416090309619904, loss=0.24862536787986755\n",
      "q:0.03882749751210213, loss=0.20200952887535095\n",
      "q:0.0420815646648407, loss=0.09372839331626892\n",
      "q:0.041304249316453934, loss=0.12524287402629852\n",
      "q:0.03939694166183472, loss=0.14041301608085632\n",
      "q:0.04068506509065628, loss=0.09289591014385223\n",
      "q:0.03822394832968712, loss=0.1417320817708969\n",
      "q:0.03803079202771187, loss=0.1414790153503418\n",
      "q:0.03564538061618805, loss=0.061854369938373566\n",
      "q:0.03771422803401947, loss=0.17201009392738342\n",
      "q:0.033631909638643265, loss=0.07867028564214706\n",
      "q:0.0405380018055439, loss=0.07944311946630478\n",
      "q:0.034360371530056, loss=0.28208625316619873\n",
      "q:0.035548143088817596, loss=0.07852508127689362\n",
      "q:0.03549491986632347, loss=0.06220779940485954\n",
      "q:0.036582183092832565, loss=0.07854442298412323\n",
      "q:0.03617050498723984, loss=0.12427195906639099\n",
      "q:0.03674129396677017, loss=0.2501375079154968\n",
      "q:0.03757321089506149, loss=0.1851557195186615\n",
      "q:0.0359012633562088, loss=0.12494082748889923\n",
      "q:0.03631169721484184, loss=0.1564580351114273\n",
      "q:0.0378747396171093, loss=0.04698661342263222\n",
      "q:0.03920672833919525, loss=0.20205707848072052\n",
      "q:0.03876056522130966, loss=0.24950575828552246\n",
      "q:0.035092297941446304, loss=0.3275774121284485\n",
      "q:0.035216569900512695, loss=0.14156842231750488\n",
      "q:0.03831872716546059, loss=0.17054276168346405\n",
      "q:0.0394212082028389, loss=0.078582763671875\n",
      "q:0.03822958469390869, loss=0.07774758338928223\n",
      "q:0.036966465413570404, loss=0.18648287653923035\n",
      "q:0.04158995673060417, loss=0.11025506258010864\n",
      "q:0.041019439697265625, loss=0.2008918821811676\n",
      "q:0.03662899509072304, loss=0.141140416264534\n",
      "q:0.03670075163245201, loss=0.10852767527103424\n",
      "q:0.04073279723525047, loss=0.2028886377811432\n",
      "q:0.0421440564095974, loss=0.23353612422943115\n",
      "q:0.04294167459011078, loss=0.04800991714000702\n",
      "q:0.040001556277275085, loss=0.3106383681297302\n",
      "q:0.041253045201301575, loss=0.07890686392784119\n",
      "q:0.04469391331076622, loss=0.10987679660320282\n",
      "q:0.04285728186368942, loss=0.20130892097949982\n",
      "q:0.04492335021495819, loss=0.23197665810585022\n",
      "q:0.0441468246281147, loss=0.09213278442621231\n",
      "q:0.04381062090396881, loss=0.17040398716926575\n",
      "q:0.04641732946038246, loss=0.15827760100364685\n",
      "q:0.04331362992525101, loss=0.3285271227359772\n",
      "q:0.04199720546603203, loss=0.0930478423833847\n",
      "q:0.04688214883208275, loss=0.20364055037498474\n",
      "q:0.04515917971730232, loss=0.07748918235301971\n",
      "q:0.04568969085812569, loss=0.06325663626194\n",
      "q:0.04572918638586998, loss=0.12552116811275482\n",
      "q:0.04655078798532486, loss=0.1412925124168396\n",
      "q:0.04487065225839615, loss=0.09534922242164612\n",
      "q:0.04097701609134674, loss=0.031201202422380447\n",
      "q:0.04464088752865791, loss=0.07791555672883987\n",
      "q:0.043010421097278595, loss=0.10781301558017731\n",
      "q:0.04292530566453934, loss=0.03248753771185875\n",
      "q:0.04489225521683693, loss=0.11009833961725235\n",
      "q:0.042684197425842285, loss=0.07935846596956253\n",
      "q:0.0426783561706543, loss=0.18662875890731812\n",
      "q:0.044277191162109375, loss=0.1084858626127243\n",
      "q:0.04043111950159073, loss=0.18592487275600433\n",
      "q:0.04165032505989075, loss=0.12543857097625732\n",
      "q:0.041951291263103485, loss=0.11042311787605286\n",
      "q:0.041337527334690094, loss=0.031157761812210083\n",
      "q:0.04083012416958809, loss=0.14083179831504822\n",
      "q:0.04083660617470741, loss=0.1702120155096054\n",
      "q:0.04120336100459099, loss=0.07768706977367401\n",
      "q:0.039352357387542725, loss=0.09297989308834076\n",
      "q:0.04090435057878494, loss=0.17265626788139343\n",
      "q:0.0349319726228714, loss=0.07815015316009521\n",
      "q:0.037240009754896164, loss=0.1870613396167755\n",
      "q:0.039805956184864044, loss=0.0626988336443901\n",
      "q:0.03959310054779053, loss=0.10891907662153244\n",
      "q:0.038368109613657, loss=0.14095479249954224\n",
      "q:0.03715689852833748, loss=0.09483553469181061\n",
      "q:0.038119006901979446, loss=0.12497209757566452\n",
      "q:0.03520018234848976, loss=0.20165766775608063\n",
      "q:0.03308124095201492, loss=0.09537481516599655\n",
      "q:0.03444250673055649, loss=0.295086532831192\n",
      "q:0.035857174545526505, loss=0.09234073013067245\n",
      "q:0.034154169261455536, loss=0.17065048217773438\n",
      "q:0.0333404615521431, loss=0.186587393283844\n",
      "q:0.02976151369512081, loss=0.09416840970516205\n",
      "q:0.03300825506448746, loss=0.015278763137757778\n",
      "q:0.03223516792058945, loss=0.1721603274345398\n",
      "q:0.036586880683898926, loss=0.12411749362945557\n",
      "q:0.03821180388331413, loss=0.29733049869537354\n",
      "q:0.03160742670297623, loss=0.03136763721704483\n",
      "q:0.034724161028862, loss=0.1408158838748932\n",
      "q:0.03495433181524277, loss=0.24760526418685913\n",
      "q:0.03397378325462341, loss=0.01523833442479372\n",
      "q:0.034252528101205826, loss=0.14119398593902588\n",
      "q:0.034251995384693146, loss=0.2476973533630371\n",
      "q:0.038555808365345, loss=0.09266944229602814\n",
      "q:0.036479800939559937, loss=0.04476287588477135\n",
      "q:0.035101331770420074, loss=0.1726401001214981\n",
      "q:0.038915082812309265, loss=0.15517285466194153\n",
      "q:0.037676505744457245, loss=0.1725873500108719\n",
      "q:0.04074074327945709, loss=0.09239669144153595\n",
      "q:0.04197516292333603, loss=0.07616935670375824\n",
      "q:0.04142788052558899, loss=0.06279782205820084\n",
      "q:0.04210754111409187, loss=0.17150461673736572\n",
      "q:0.03994201868772507, loss=0.12342914193868637\n",
      "q:0.04332089424133301, loss=0.10755043476819992\n",
      "q:0.04540933668613434, loss=0.17131373286247253\n",
      "q:0.03770115226507187, loss=0.10741756111383438\n",
      "q:0.04363542050123215, loss=0.1102762520313263\n",
      "q:0.04489772766828537, loss=0.03150792792439461\n",
      "q:0.0398118831217289, loss=0.11158857494592667\n",
      "q:0.03763397037982941, loss=0.07557225972414017\n",
      "q:0.04747999459505081, loss=0.2617338299751282\n",
      "q:0.048605211079120636, loss=0.26241424679756165\n",
      "q:0.04446736350655556, loss=0.07992896437644958\n",
      "q:0.049465760588645935, loss=0.11214941740036011\n",
      "q:0.04990953207015991, loss=0.1563563346862793\n",
      "q:0.04504472017288208, loss=0.09699035435914993\n",
      "q:0.03911716118454933, loss=0.12706191837787628\n",
      "q:0.04507801681756973, loss=0.09446845948696136\n",
      "q:0.04231925308704376, loss=0.15585263073444366\n",
      "q:0.04723239317536354, loss=0.07917768508195877\n",
      "q:0.040504902601242065, loss=0.07933767139911652\n",
      "q:0.03799877315759659, loss=0.13856784999370575\n",
      "q:0.03596211224794388, loss=0.029926802963018417\n",
      "q:0.04015099257230759, loss=0.07870936393737793\n",
      "q:0.036790113896131516, loss=0.10923320800065994\n",
      "q:0.03877491503953934, loss=0.12471335381269455\n",
      "q:0.04140797629952431, loss=0.09367071837186813\n",
      "q:0.03990229219198227, loss=0.10588370263576508\n",
      "q:0.040242888033390045, loss=0.09166085720062256\n",
      "q:0.038697436451911926, loss=0.10874538868665695\n",
      "q:0.04495086520910263, loss=0.26450496912002563\n",
      "q:0.0397970974445343, loss=0.04798947274684906\n",
      "q:0.03862588852643967, loss=0.14023101329803467\n",
      "q:0.045138951390981674, loss=0.047512032091617584\n",
      "q:0.040640272200107574, loss=0.1545923352241516\n",
      "q:0.03496778756380081, loss=0.10888754576444626\n",
      "q:0.037913598120212555, loss=0.1386777013540268\n",
      "q:0.0391974151134491, loss=0.11124001443386078\n",
      "q:0.039169542491436005, loss=0.2038940042257309\n",
      "q:0.038707185536623, loss=0.21869981288909912\n",
      "q:0.03660932183265686, loss=0.17101022601127625\n",
      "q:0.03851362317800522, loss=0.06440342962741852\n",
      "q:0.04220692813396454, loss=0.04870446026325226\n",
      "q:0.04236902669072151, loss=0.03284189850091934\n",
      "q:0.03645350784063339, loss=0.13995489478111267\n",
      "q:0.03666255623102188, loss=0.10763751715421677\n",
      "q:0.04333125427365303, loss=0.10764903575181961\n",
      "q:0.03905107080936432, loss=0.04601582884788513\n",
      "q:0.038761917501688004, loss=0.061420150101184845\n",
      "q:0.0372479185461998, loss=0.23197512328624725\n",
      "q:0.03913528844714165, loss=0.09346996247768402\n",
      "q:0.03886742144823074, loss=0.04860096424818039\n",
      "q:0.03792387247085571, loss=0.06273670494556427\n",
      "q:0.03160755708813667, loss=0.1714688539505005\n",
      "q:0.038869597017765045, loss=0.10856784880161285\n",
      "q:0.03671492636203766, loss=0.06269194930791855\n",
      "q:0.03627840429544449, loss=0.04764864966273308\n",
      "q:0.040410593152046204, loss=0.030180979520082474\n",
      "q:0.03429713845252991, loss=0.21768327057361603\n",
      "q:0.03881620243191719, loss=0.09340707212686539\n",
      "q:0.040308281779289246, loss=0.062318913638591766\n",
      "q:0.028551016002893448, loss=0.06315340846776962\n",
      "q:0.03880937397480011, loss=0.18668857216835022\n",
      "q:0.04112296551465988, loss=0.15701715648174286\n",
      "q:0.040859706699848175, loss=0.1572483479976654\n",
      "q:0.03193293511867523, loss=0.17080332338809967\n",
      "q:0.03406592458486557, loss=0.17101365327835083\n",
      "q:0.037647098302841187, loss=0.07738178968429565\n",
      "q:0.03823516517877579, loss=0.12449568510055542\n",
      "q:0.03361930325627327, loss=0.15501214563846588\n",
      "q:0.031716831028461456, loss=0.07857780903577805\n",
      "q:0.035209234803915024, loss=0.06148466840386391\n",
      "q:0.032254837453365326, loss=0.0618051216006279\n",
      "q:0.029676241800189018, loss=0.06233665347099304\n",
      "q:0.030887391418218613, loss=0.0946655422449112\n",
      "q:0.03224141523241997, loss=0.03154481574892998\n",
      "q:0.038562335073947906, loss=0.0784793347120285\n",
      "q:0.035936981439590454, loss=0.15682891011238098\n",
      "q:0.029378142207860947, loss=0.09212124347686768\n",
      "q:0.036202799528837204, loss=0.04735686257481575\n",
      "q:0.027402687817811966, loss=0.21951092779636383\n",
      "q:0.029450468719005585, loss=0.07770387828350067\n",
      "q:0.031438931822776794, loss=0.2639123499393463\n",
      "q:0.03205408155918121, loss=0.14090722799301147\n",
      "q:0.03558703511953354, loss=0.1867857426404953\n",
      "q:0.03623268008232117, loss=0.09289032965898514\n",
      "q:0.03295028582215309, loss=0.17422503232955933\n",
      "q:0.02988947182893753, loss=0.14206597208976746\n",
      "q:0.031050262972712517, loss=0.14001968502998352\n",
      "q:0.03116660751402378, loss=0.17255699634552002\n",
      "q:0.03448402136564255, loss=0.1705232858657837\n",
      "q:0.03591463342308998, loss=0.10776013135910034\n",
      "q:0.03206581994891167, loss=0.14011335372924805\n",
      "q:0.03336544707417488, loss=0.18584869801998138\n",
      "q:0.0310740377753973, loss=0.18683767318725586\n",
      "q:0.03521709889173508, loss=0.18814638257026672\n",
      "q:0.029503244906663895, loss=0.14035364985466003\n",
      "q:0.032704006880521774, loss=0.07748383283615112\n",
      "q:0.026322070509195328, loss=0.06356463581323624\n",
      "q:0.037458088248968124, loss=0.0929979681968689\n",
      "q:0.03798750787973404, loss=0.24859365820884705\n",
      "q:0.035124290734529495, loss=0.12491337209939957\n",
      "q:0.03479653596878052, loss=0.1259600818157196\n",
      "q:0.035791464149951935, loss=0.11032537370920181\n",
      "q:0.035246722400188446, loss=0.14023315906524658\n",
      "q:0.034826457500457764, loss=0.1254391223192215\n",
      "q:0.038666848093271255, loss=0.0945441871881485\n",
      "q:0.03914656490087509, loss=0.07664662599563599\n",
      "q:0.03457677364349365, loss=0.09375874698162079\n",
      "q:0.03230127692222595, loss=0.0001112204699893482\n",
      "q:0.034552402794361115, loss=0.07993269711732864\n",
      "q:0.032770805060863495, loss=0.07921841740608215\n",
      "q:0.032534170895814896, loss=0.09344072639942169\n",
      "q:0.037679679691791534, loss=0.1402440071105957\n",
      "q:0.03525112196803093, loss=0.26481491327285767\n",
      "q:0.03833615034818649, loss=0.2025560587644577\n",
      "q:0.03407676890492439, loss=0.1098514124751091\n",
      "q:0.03336048498749733, loss=0.01607106439769268\n",
      "q:0.03668496757745743, loss=0.07849204540252686\n",
      "q:0.037039607763290405, loss=0.1099439412355423\n",
      "q:0.03439103439450264, loss=0.15492546558380127\n",
      "q:0.03774493560194969, loss=0.07774661481380463\n",
      "q:0.03700171411037445, loss=0.18974456191062927\n",
      "q:0.03995274007320404, loss=0.31067997217178345\n",
      "q:0.03765754774212837, loss=0.1878226101398468\n",
      "q:0.04053162783384323, loss=0.13883499801158905\n",
      "q:0.03728831931948662, loss=0.12421097606420517\n",
      "q:0.041266705840826035, loss=0.07747918367385864\n",
      "q:0.04226696491241455, loss=0.047107234597206116\n",
      "q:0.03980886936187744, loss=0.07826046645641327\n",
      "q:0.04246262088418007, loss=0.10950986295938492\n",
      "q:0.04324067384004593, loss=0.04841071367263794\n",
      "q:0.04354154318571091, loss=0.10777301341295242\n",
      "q:0.04190575331449509, loss=0.15471497178077698\n",
      "q:0.03979606181383133, loss=0.04645552486181259\n",
      "q:0.04111166670918465, loss=0.000177418056409806\n",
      "q:0.040294140577316284, loss=0.06184469908475876\n",
      "q:0.03861391916871071, loss=0.07715915888547897\n",
      "q:0.042050547897815704, loss=0.12323836982250214\n",
      "q:0.04259831830859184, loss=0.15608394145965576\n",
      "q:0.041711173951625824, loss=0.12369440495967865\n",
      "q:0.04044795036315918, loss=0.1713043749332428\n",
      "q:0.04116395115852356, loss=0.1386091262102127\n",
      "q:0.03848891705274582, loss=0.09210409224033356\n",
      "q:0.040879085659980774, loss=0.07962791621685028\n",
      "q:0.04002431407570839, loss=0.060196246951818466\n",
      "q:0.03979409113526344, loss=0.10759264975786209\n",
      "q:0.039115533232688904, loss=0.2014724314212799\n",
      "q:0.040410641580820084, loss=0.18732386827468872\n",
      "q:0.04108380526304245, loss=0.04754689335823059\n",
      "q:0.04043193161487579, loss=0.1249205470085144\n",
      "q:0.041325852274894714, loss=0.21867626905441284\n",
      "q:0.042008381336927414, loss=0.26483747363090515\n",
      "q:0.03984865918755531, loss=0.06170564144849777\n",
      "q:0.03885117918252945, loss=0.0944078266620636\n",
      "q:0.03700152784585953, loss=0.04625234752893448\n",
      "q:0.037271782755851746, loss=0.06128985434770584\n",
      "q:0.037892259657382965, loss=0.14174436032772064\n",
      "q:0.0347297266125679, loss=0.26415008306503296\n",
      "q:0.037369031459093094, loss=0.04786008596420288\n",
      "q:0.03978419303894043, loss=0.07787152379751205\n",
      "q:0.03840067610144615, loss=0.030393773689866066\n",
      "q:0.03737904131412506, loss=0.09364935755729675\n",
      "q:0.03753194957971573, loss=0.11050424724817276\n",
      "q:0.03775626793503761, loss=0.10905618220567703\n",
      "q:0.037969037890434265, loss=0.10896731913089752\n",
      "q:0.037331774830818176, loss=0.06282367557287216\n",
      "q:0.039212990552186966, loss=0.04702354222536087\n",
      "q:0.03723730146884918, loss=0.1409301608800888\n",
      "q:0.03718746080994606, loss=0.15580636262893677\n",
      "q:0.034712694585323334, loss=0.20061229169368744\n",
      "q:0.034646663814783096, loss=0.13837313652038574\n",
      "q:0.036063842475414276, loss=0.1863488256931305\n",
      "q:0.03544158861041069, loss=0.09315041452646255\n",
      "q:0.03311139717698097, loss=0.12520241737365723\n",
      "q:0.034128881990909576, loss=0.046413589268922806\n",
      "q:0.0328977108001709, loss=0.031760185956954956\n",
      "q:0.031771283596754074, loss=0.09304449707269669\n",
      "q:0.03173403441905975, loss=0.04749318212270737\n",
      "q:0.033124469220638275, loss=0.11125838756561279\n",
      "q:0.03162778913974762, loss=0.1253872811794281\n",
      "q:0.03208579123020172, loss=0.18828320503234863\n",
      "q:0.03127007931470871, loss=0.12611936032772064\n",
      "q:0.027380026876926422, loss=0.1718134880065918\n",
      "q:0.029696056619286537, loss=0.15537475049495697\n",
      "q:0.024795055389404297, loss=0.12594819068908691\n",
      "q:0.023612281307578087, loss=0.1714315265417099\n",
      "q:0.024233516305685043, loss=0.046764545142650604\n",
      "q:0.02426190860569477, loss=0.17221875488758087\n",
      "q:0.025040127336978912, loss=0.1094484031200409\n",
      "q:0.02604740485548973, loss=0.01585480011999607\n",
      "q:0.024697139859199524, loss=0.28086933493614197\n",
      "q:0.02609587088227272, loss=0.1255062073469162\n",
      "q:0.025962844491004944, loss=0.10880999267101288\n",
      "q:0.027372201904654503, loss=0.03224581107497215\n",
      "q:0.023858217522501945, loss=0.06278407573699951\n",
      "q:0.025565896183252335, loss=0.20311392843723297\n",
      "q:0.02561729960143566, loss=0.04645891487598419\n",
      "q:0.02518364042043686, loss=0.17107339203357697\n",
      "q:0.02561802789568901, loss=0.11029436439275742\n",
      "q:0.028074270114302635, loss=0.047378476709127426\n",
      "q:0.026901988312602043, loss=0.030645539984107018\n",
      "q:0.027424108237028122, loss=0.015452773310244083\n",
      "q:0.027135681360960007, loss=0.187220498919487\n",
      "q:0.027950555086135864, loss=0.07766567170619965\n",
      "q:0.02970787324011326, loss=0.07787826657295227\n",
      "q:0.0299273282289505, loss=0.06200267747044563\n",
      "q:0.03151557594537735, loss=0.12432064116001129\n",
      "q:0.028215307742357254, loss=0.10988245159387589\n",
      "q:0.030475765466690063, loss=0.1544022411108017\n",
      "q:0.03140277788043022, loss=0.109188012778759\n",
      "q:0.03163190931081772, loss=0.24980974197387695\n",
      "q:0.03244525194168091, loss=0.0783599466085434\n",
      "q:0.028914552181959152, loss=0.15535593032836914\n",
      "q:0.03274589776992798, loss=0.20276376605033875\n",
      "q:0.03343780338764191, loss=0.06220589205622673\n",
      "q:0.031380414962768555, loss=0.109848253428936\n",
      "q:0.031754180788993835, loss=0.14023013412952423\n",
      "q:0.02964334562420845, loss=0.04722822830080986\n",
      "q:0.03193294256925583, loss=0.12473637610673904\n",
      "q:0.032149236649274826, loss=0.06235920265316963\n",
      "q:0.0318467915058136, loss=0.06259848177433014\n",
      "q:0.03216227889060974, loss=0.10878080129623413\n",
      "q:0.03486467897891998, loss=0.09271380305290222\n",
      "q:0.032123398035764694, loss=0.07701980322599411\n",
      "q:0.0318937674164772, loss=0.046613436192274094\n",
      "q:0.03268953412771225, loss=0.12596255540847778\n",
      "q:0.032373376190662384, loss=0.1249467134475708\n",
      "q:0.03180680796504021, loss=0.04730122536420822\n",
      "q:0.029687412083148956, loss=0.12487182021141052\n",
      "q:0.02566150575876236, loss=0.09210609644651413\n",
      "q:0.022270429879426956, loss=0.07852904498577118\n",
      "q:0.020642023533582687, loss=0.03236977010965347\n",
      "q:0.023331739008426666, loss=0.1722865104675293\n",
      "q:0.021243805065751076, loss=0.13928483426570892\n",
      "q:0.02598903514444828, loss=0.03133317455649376\n",
      "q:0.022423909977078438, loss=0.0632590726017952\n",
      "q:0.02288264036178589, loss=0.030152631923556328\n",
      "q:0.026671987026929855, loss=0.14064502716064453\n",
      "q:0.023233257234096527, loss=0.1880321055650711\n",
      "q:0.02007175050675869, loss=0.11011427640914917\n",
      "q:0.023453861474990845, loss=0.06210292875766754\n",
      "q:0.021000821143388748, loss=0.12636879086494446\n",
      "q:0.024471469223499298, loss=0.14194875955581665\n",
      "q:0.02140437252819538, loss=0.06280717998743057\n",
      "q:0.025107521563768387, loss=0.11067746579647064\n",
      "q:0.026817459613084793, loss=0.1093929260969162\n",
      "q:0.02810385450720787, loss=0.10903049260377884\n",
      "q:0.02461974322795868, loss=0.04840531945228577\n",
      "q:0.025927912443876266, loss=0.20184259116649628\n",
      "q:0.023794177919626236, loss=0.1086992472410202\n",
      "q:0.030667457729578018, loss=0.09396345913410187\n",
      "q:0.028956588357686996, loss=0.04687151312828064\n",
      "q:0.02638225071132183, loss=0.03150879591703415\n",
      "q:0.024890724569559097, loss=0.015435604378581047\n",
      "q:0.02812664955854416, loss=0.14025074243545532\n",
      "q:0.026484720408916473, loss=0.06183064728975296\n",
      "q:0.02846268191933632, loss=0.0625355914235115\n",
      "q:0.025951562449336052, loss=0.031230110675096512\n",
      "q:0.02776719257235527, loss=0.09357015788555145\n",
      "q:0.02700703591108322, loss=0.1409309208393097\n",
      "q:0.024910636246204376, loss=0.030924919992685318\n",
      "q:0.025143427774310112, loss=0.09295669198036194\n",
      "q:0.027359265834093094, loss=0.12604552507400513\n",
      "q:0.027455486357212067, loss=0.046472128480672836\n",
      "q:0.027363214641809464, loss=0.10964615643024445\n",
      "q:0.027774911373853683, loss=0.06239461526274681\n",
      "q:0.026157323271036148, loss=0.2027859091758728\n",
      "q:0.027302179485559464, loss=0.20277677476406097\n",
      "q:0.02578497864305973, loss=0.061255402863025665\n",
      "q:0.02644554153084755, loss=0.18728171288967133\n",
      "q:0.025879984721541405, loss=0.17106902599334717\n",
      "q:0.025437649339437485, loss=0.09404715895652771\n",
      "q:0.02633507177233696, loss=3.735570135177113e-05\n",
      "q:0.026453470811247826, loss=0.03132275491952896\n",
      "q:0.02502610720694065, loss=0.17190808057785034\n",
      "q:0.025902707129716873, loss=0.09332296252250671\n",
      "q:0.024150485172867775, loss=0.2498583197593689\n",
      "q:0.025685783475637436, loss=0.015762578696012497\n",
      "q:0.021808169782161713, loss=0.2505201995372772\n",
      "q:0.025639047846198082, loss=0.10847033560276031\n",
      "q:0.025071561336517334, loss=0.07742707431316376\n",
      "q:0.023378517478704453, loss=0.031044920906424522\n",
      "q:0.02389436773955822, loss=0.046569548547267914\n",
      "q:0.024597153067588806, loss=0.031033817678689957\n",
      "q:0.02335674688220024, loss=0.14102675020694733\n",
      "q:0.022585878148674965, loss=0.030911002308130264\n",
      "q:0.025141935795545578, loss=0.10788973420858383\n",
      "q:0.024536047130823135, loss=0.06220594421029091\n",
      "q:0.022078074514865875, loss=0.09346361458301544\n",
      "q:0.023132268339395523, loss=0.12383656948804855\n",
      "q:0.021570373326539993, loss=0.2343849539756775\n",
      "q:0.022259870544075966, loss=0.1081043928861618\n",
      "q:0.024165064096450806, loss=0.10813374817371368\n",
      "q:0.023673780262470245, loss=0.2963661551475525\n",
      "q:0.022830327972769737, loss=0.18780545890331268\n",
      "q:0.020203126594424248, loss=0.04625170677900314\n",
      "q:0.019981749355793, loss=0.03091234527528286\n",
      "q:0.020989561453461647, loss=0.1553877741098404\n",
      "q:0.020252227783203125, loss=0.07647238671779633\n",
      "q:0.01954442262649536, loss=0.1416013240814209\n",
      "q:0.016994839534163475, loss=0.18662679195404053\n",
      "q:0.018657052889466286, loss=0.09438884258270264\n",
      "q:0.017881836742162704, loss=0.15647831559181213\n",
      "q:0.016953622922301292, loss=0.10856345295906067\n",
      "q:0.018049828708171844, loss=0.10888312011957169\n",
      "q:0.017668049782514572, loss=0.07901733368635178\n",
      "q:0.018290003761649132, loss=0.09278790652751923\n",
      "q:0.017785273492336273, loss=0.23198102414608002\n",
      "q:0.017694778740406036, loss=0.10970766842365265\n",
      "q:0.01873452216386795, loss=0.11012628674507141\n",
      "q:0.020175570622086525, loss=0.015381972305476665\n",
      "q:0.018320489674806595, loss=0.28217440843582153\n",
      "q:0.018725814297795296, loss=0.1560252159833908\n",
      "q:0.020397700369358063, loss=0.1889335960149765\n",
      "q:0.01949159987270832, loss=0.0633176788687706\n",
      "q:0.019897691905498505, loss=0.07787497341632843\n",
      "q:0.02029920183122158, loss=0.17203989624977112\n",
      "q:0.019870411604642868, loss=0.17162415385246277\n",
      "q:0.02015579864382744, loss=0.07638636231422424\n",
      "q:0.021926697343587875, loss=0.04660237953066826\n",
      "q:0.02040957286953926, loss=0.032462410628795624\n",
      "q:0.019875332713127136, loss=0.09289804100990295\n",
      "q:0.02197757177054882, loss=0.10969679057598114\n",
      "q:0.023024698719382286, loss=0.23405329883098602\n",
      "q:0.021023418754339218, loss=0.1853456050157547\n",
      "q:0.021004965528845787, loss=0.09381919354200363\n",
      "q:0.021786343306303024, loss=0.18785464763641357\n",
      "q:0.020847138017416, loss=0.1076543778181076\n",
      "q:0.020997216925024986, loss=0.1082703173160553\n",
      "q:0.020999953150749207, loss=0.12465009093284607\n",
      "q:0.02256251871585846, loss=0.10870709270238876\n",
      "q:0.02185644954442978, loss=0.17132312059402466\n",
      "q:0.021538132801651955, loss=0.12331893295049667\n",
      "q:0.019249215722084045, loss=0.061457082629203796\n",
      "q:0.022096365690231323, loss=0.18903879821300507\n",
      "q:0.022090725600719452, loss=0.06178290769457817\n",
      "q:0.021981529891490936, loss=0.07673077285289764\n",
      "q:0.021492669358849525, loss=0.15607567131519318\n",
      "q:0.01887514442205429, loss=0.06195862591266632\n",
      "q:0.021609321236610413, loss=0.029969889670610428\n",
      "q:0.022102955728769302, loss=0.18719080090522766\n",
      "q:0.022535430267453194, loss=0.09324491769075394\n",
      "q:0.019286084920167923, loss=0.015092664398252964\n",
      "q:0.021561846137046814, loss=0.20292356610298157\n",
      "q:0.022337935864925385, loss=0.09351642429828644\n",
      "q:0.021301858127117157, loss=0.10815466195344925\n",
      "q:0.01917402818799019, loss=0.06247877702116966\n",
      "q:0.02096645161509514, loss=0.07790938019752502\n",
      "q:0.0177801251411438, loss=0.030218616127967834\n",
      "q:0.02109765261411667, loss=0.12404376268386841\n",
      "q:0.02137768268585205, loss=0.2196401059627533\n",
      "q:0.022494886070489883, loss=0.03092437982559204\n",
      "q:0.02411310374736786, loss=0.0623461976647377\n",
      "q:0.01980159431695938, loss=0.0792354866862297\n",
      "q:0.02336944080889225, loss=0.03112427331507206\n",
      "q:0.023150350898504257, loss=0.047090690582990646\n",
      "q:0.01816735416650772, loss=0.14105841517448425\n",
      "q:0.02098141424357891, loss=8.903556590666994e-05\n",
      "q:0.02301071584224701, loss=0.07867973297834396\n",
      "q:0.02272426337003708, loss=0.10813211649656296\n",
      "q:0.021822454407811165, loss=0.06292275339365005\n",
      "q:0.023854047060012817, loss=0.12445205450057983\n",
      "q:0.023677216842770576, loss=0.04687933623790741\n",
      "q:0.02091744914650917, loss=0.06188290938735008\n",
      "q:0.021008936688303947, loss=0.10687947273254395\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14868\\3627309936.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetAction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# add to memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gymnes\\lib\\site-packages\\gym\\wrappers\\frame_stack.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gymnes\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gymnes\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gymnes\\lib\\site-packages\\nes_py\\wrappers\\joypad_space.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \"\"\"\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# take the step and record the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_action_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gymnes\\lib\\site-packages\\gym\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         ), \"Cannot call env.step() before calling reset()\"\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gymnes\\lib\\site-packages\\nes_py\\nes_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrollers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[1;31m# pass the action to the emulator as an unsigned byte\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[1;31m# get the reward for this step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_reward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# try training\n",
    "\n",
    "maxSteps = 10000\n",
    "done = True\n",
    "learnCount = 0\n",
    "\n",
    "for i in range(maxSteps):\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "    \n",
    "    action = agent.getAction(state)\n",
    "    next_state, reward, done, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    # add to memory\n",
    "    agent.cache(state, next_state, action, reward, done)\n",
    "    \n",
    "    q, loss = agent.learn()\n",
    "    \n",
    "    \n",
    "    if q is not None:\n",
    "        learnCount += 1\n",
    "        if learnCount % 100:\n",
    "            print(f\"q:{q}, loss={loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, next_states, actions, rewards, dones = agent.sampleExperienceBatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5, 50, 50])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,\n",
      "        -2,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
